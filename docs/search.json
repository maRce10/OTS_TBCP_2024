[
  {
    "objectID": "r_basics.html",
    "href": "r_basics.html",
    "title": "Basic elements of the R language",
    "section": "",
    "text": "To understand the basic blocks used in R programming\nTo become familiar with the main sources of standardized documentation in R"
  },
  {
    "objectID": "r_basics.html#section",
    "href": "r_basics.html#section",
    "title": "Basic elements of the R language",
    "section": "2.1  ",
    "text": "2.1"
  },
  {
    "objectID": "r_basics.html#objects-containing-data",
    "href": "r_basics.html#objects-containing-data",
    "title": "Basic elements of the R language",
    "section": "3.1 Objects containing data",
    "text": "3.1 Objects containing data\nThe basic data structure in R is the vector. With this all other object classes are built. To understand classes it is useful to think about the number of dimensions (1, 2 or more) and types of data they can contain: homogeneous (a single element type) or heterogeneous (or multiple element types).\n\n\n\n\n\nflowchart LR\n    classDef largeText font-size:18px, padding:15px;\n\n    D(Data objects) --&gt; D1(1 dimension)\n    D --&gt; D2(2 dimensions)\n    D1 --&gt; V(Vector)\n    D1 --&gt; L(List)\n    D2 --&gt; M(Matrix)\n    D2 --&gt;  DF(Data Frame)\n\n    style D fill:#40498E66, stroke:#000, stroke-width:2px, color:#FFF, width:180px\n    style D1 fill:#348AA666, stroke:#000, stroke-width:2px, color:#FFF, width:140px\n    style D2 fill:#348AA666, stroke:#000, stroke-width:2px, color:#FFF, width:140px\n    style DF fill:#49C1AD66, stroke:#000, stroke-width:2px, color:#000\n    style V fill:#49C1AD66, stroke:#000, stroke-width:2px, color:#000\n    style M fill:#49C1AD66, stroke:#000, stroke-width:2px, color:#000\n    style L fill:#49C1AD66, stroke:#000, stroke-width:2px, color:#000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomogeneous\nHeterogeneous\n\n\n\n\n1d\nAtomic vector\nList\n\n\n2d\nMatrix\nData frame\n\n\nnd\nArray\n\n\n\n\n\n\n\n\n3.1.1 1 dimension objects\nThere are two basic types of vectors: atomic vectors and lists.\nThey have three common properties:\n\nType, typeof() (class/mode).\nLength, length() (number of elements)\nAttributes, attributes() (metadata)\n\nThey differ in the types of their elements: all elements of an atomic vector must be of the same type, while the elements of a list can have different types.\n\n3.1.1.1 Atomic vectors\nTypes of atomic vectors:\n\nLogical (Boolean)\nInteger\nNumeric (double)\nCharacters\nFactors\n\nVectors are constructed with the c() function, they can be numeric:\n\n\nCode\nx &lt;- 1\nx1 &lt;- c(1)\n\nall.equal(x, x1)\n\n\n[1] TRUE\n\n\nCode\nclass(x)\n\n\n[1] \"numeric\"\n\n\nCharacters:\n\n\nCode\ny &lt;- \"something\"\n\nclass(y)\n\n\n[1] \"character\"\n\n\nLogical:\n\n\nCode\nz &lt;- TRUE\n\nclass(z)\n\n\n[1] \"logical\"\n\n\nOr factor:\n\n\nCode\nq &lt;- factor(1)\n\nclass(q)\n\n\n[1] \"factor\"\n\n\nTherefore, the individual numbers or strings are actually vectors of length one:\n\n\nCode\nclass(1)\n\n\n[1] \"numeric\"\n\n\nCode\nclass(\"a\")\n\n\n[1] \"character\"\n\n\nVectors can only contain elements of the same type. Different types of elements will be forced to the most flexible type:\n\n\nCode\nx &lt;- c(1, 2, \"a\")\n\nx\n\n\n[1] \"1\" \"2\" \"a\"\n\n\nCode\nclass(x)\n\n\n[1] \"character\"\n\n\nMissing values are specified with NA, which is a logical vector of length 1. NA will always be interpreted to the correct type if used inside c():\n\n\nCode\nv &lt;- c(10, 11, NA)\n\nclass(v)\n\n\n[1] \"numeric\"\n\n\nCode\nv &lt;- c(\"a\", \"b\", NA)\n\nclass(v)\n\n\n[1] \"character\"\n\n\n\n\n\n3.1.1.2 Factors\nVectors with factors are very similar to character vectors. However, a factor can only contain predefined values, known as levels. Attributes are used to define the levels of the factor.\nFactors are built on integer vectors using two attributes:\n\n“factor” class: makes them behave differently from normal character vectors.\nlevels: defines the set of allowed values\n\n\n\nCode\nx &lt;- factor(c(\"a\", \"b\", \"b\", \"a\"))\nx\n\n\n[1] a b b a\nLevels: a b\n\n\nCode\nlevels(x)\n\n\n[1] \"a\" \"b\"\n\n\nCode\nstr(x)\n\n\n Factor w/ 2 levels \"a\",\"b\": 1 2 2 1\n\n\nThe factors look like character vectors, but are actually integers:\n\n\nCode\nx &lt;- factor(c(\"a\", \"b\", \"b\", \"a\"))\n\nc(x)\n\n\n[1] a b b a\nLevels: a b\n\n\n\n\n3.1.1.3 Lists\nCan contain objects of different classes and sizes. Lists are constructed with list():\n\n\nCode\nl &lt;- list(\"a\", 1, FALSE)\n\nl\n\n\n[[1]]\n[1] \"a\"\n\n[[2]]\n[1] 1\n\n[[3]]\n[1] FALSE\n\n\nCode\nclass(l)\n\n\n[1] \"list\"\n\n\nCode\nstr(l)\n\n\nList of 3\n $ : chr \"a\"\n $ : num 1\n $ : logi FALSE\n\n\nIn fact, they can be seen as drawers where you can put any other type of object:\n\n\nCode\nl &lt;- list(c(\"a\", \"b\"), \n          c(1, 2, 3, 4), \n          c(FALSE, TRUE, FALSE))\n\nl\n\n\n[[1]]\n[1] \"a\" \"b\"\n\n[[2]]\n[1] 1 2 3 4\n\n[[3]]\n[1] FALSE  TRUE FALSE\n\n\nCode\nstr(l)\n\n\nList of 3\n $ : chr [1:2] \"a\" \"b\"\n $ : num [1:4] 1 2 3 4\n $ : logi [1:3] FALSE TRUE FALSE\n\n\n\n\n\n3.1.2 2-dimensional objects\n\n3.1.2.1 Matrices\nAll elements are of the same type:\n\n\nCode\nm &lt;- matrix(c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"), nrow = 2)\n\ndim(m)\n\n\n[1] 2 3\n\n\nCode\nm\n\n\n     [,1] [,2] [,3]\n[1,] \"a\"  \"c\"  \"e\" \n[2,] \"b\"  \"d\"  \"f\" \n\n\nCode\nclass(m)\n\n\n[1] \"matrix\" \"array\" \n\n\nCode\nm &lt;- matrix(c(\"a\", \"b\", \"c\", \"d\", \"e\", 1), nrow = 2)\nm\n\n\n     [,1] [,2] [,3]\n[1,] \"a\"  \"c\"  \"e\" \n[2,] \"b\"  \"d\"  \"1\" \n\n\n\n\n3.1.2.2 Data Frames\nSpecial case of lists. It can contain elements of different types:\n\n\nCode\nm &lt;-\n  data.frame(\n    ID = c(\"a\", \"b\", \"c\", \"d\", \"e\"),\n    size = c(1, 2, 3, 4, 5),\n    observed = c(FALSE, TRUE, FALSE, FALSE, FALSE)\n  )\n\ndim(m)\n\n\n[1] 5 3\n\n\nCode\nm\n\n\n\n\n\n\nID\nsize\nobserved\n\n\n\n\na\n1\nFALSE\n\n\nb\n2\nTRUE\n\n\nc\n3\nFALSE\n\n\nd\n4\nFALSE\n\n\ne\n5\nFALSE\n\n\n\n\n\n\nCode\nclass(m)\n\n\n[1] \"data.frame\"\n\n\nCode\nis.data.frame(m)\n\n\n[1] TRUE\n\n\nCode\nis.list(m)\n\n\n[1] TRUE\n\n\nCode\nstr(m)\n\n\n'data.frame':   5 obs. of  3 variables:\n $ ID      : chr  \"a\" \"b\" \"c\" \"d\" ...\n $ size    : num  1 2 3 4 5\n $ observed: logi  FALSE TRUE FALSE FALSE FALSE\n\n\nBut the vectors must have the same length:\n\n\nCode\nm &lt;-\n  data.frame(\n    ID = c(\"a\", \"b\", \"c\", \"d\", \"e\"),\n    size = c(1, 2, 3, 4, 5, 6),\n    observed = c(FALSE, TRUE, FALSE, FALSE, FALSE)\n  )\n\n\nError in data.frame(ID = c(\"a\", \"b\", \"c\", \"d\", \"e\"), size = c(1, 2, 3, : arguments imply differing number of rows: 5, 6"
  },
  {
    "objectID": "r_basics.html#exercise-1",
    "href": "r_basics.html#exercise-1",
    "title": "Basic elements of the R language",
    "section": "3.2 Exercise 1",
    "text": "3.2 Exercise 1\n\nCreate a numeric vector with 8 elements containing positive and negative numbers.\nCreate a character vector with the names of the provinces of Costa Rica.\nAdd to the above point vector an NA\nCreate a numeric matrix with 3 columns and 3 rows\nCreate a character matrix with 4 columns and 3 rows\nWhat class of object is ‘iris’ and what are its dimensions (hint: iris is an object available by default in your environment)?\nCreate a data frame with a numeric column, a character column and a factor column."
  },
  {
    "objectID": "r_basics.html#functions-objects-that-perform-tasks",
    "href": "r_basics.html#functions-objects-that-perform-tasks",
    "title": "Basic elements of the R language",
    "section": "3.3 Functions: objects that perform tasks",
    "text": "3.3 Functions: objects that perform tasks\nAll functions are created with the function() function and follow the same structure:\n\n* Modified from Grolemund 2014  \n\n3.3.1 Integrated functions\n\n3.3.1.1 Basic functions\nR comes with many functions that you can use to do sophisticated tasks:\n\n\nCode\n# built in functions\nbi &lt;- builtins(internal = FALSE)\n\nlength(bi)\n\n\n[1] 1388\n\n\nSome functions come by default with R basic. New functions can be loaded as part of additional packages or even created by the user.\n\n\n\n\n\nflowchart LR\n    classDef largeText font-size:18px, padding:15px;\n\n    F(Functions) --&gt; BF(Integraded functions)\n    BF --&gt; OP(Operators)\n    BF --&gt; BA(Basic functions)\n    F --&gt; PF(Packages)\n    F --&gt; UF(User defined functions)\n\n    class R,D,D1,D2,F largeText;\n\n    style F fill:#357BA266, stroke:#000, stroke-width:2px, color:#FFF, width:120px\n    style BF fill:#A0DFB966, stroke:#000, stroke-width:2px, color:#000\n    style BA fill:#DEF5E566, stroke:#000, stroke-width:2px, color:#000\n    style OP fill:#DEF5E566, stroke:#000, stroke-width:2px, color:#000    \n    style PF fill:#A0DFB966, stroke:#000, stroke-width:2px, color:#000000\n    style UF fill:#A0DFB966, stroke:#000, stroke-width:2px, color:#000\n\n\n\n\n\n\n\n\n\n3.3.1.2 Operators\nOperators are functions:\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\nCode\n'+'(1, 1)\n\n\n[1] 2\n\n\nCode\n2 * 3\n\n\n[1] 6\n\n\nCode\n'*'(2, 3)\n\n\n[1] 6\n\n\n\n3.3.1.2.1 Most used operators\nArithmetic operators:\n\n\n\n\n\n\nOperator\nDescription\n\n\n\n\n+\nsum\n\n\n-\nsubtraction\n\n\n*\nmultiplication\n\n\n/\ndivision\n\n\n^ or **\nexponential\n\n\n\n\n\n\n\n\n\n\nCode\n1 - 2\n\n\n[1] -1\n\n\nCode\n1 + 2\n\n\n[1] 3\n\n\nCode\n2 ^ 2\n\n\n[1] 4\n\n\nCode\n2 ** 2\n\n\n[1] 4\n\n\nCode\n2:3 %in% 2:4\n\n\n[1] TRUE TRUE\n\n\nLogical operators:\n\n\n\nOperator\nDescription\n\n\n\n\n&lt;\nlower than\n\n\n&lt;=\nlower than or equal to\n\n\n&gt;\nhigher than\n\n\n&gt;=\nhigher than or equal to\n\n\n==\nexactly the same\n\n\n!=\ndifferent than\n\n\n!x\nIs not x\n\n\nx | y\nx O y\n\n\nx & y\nx Y y\n\n\nx %in% y\ncorrespondence\n\n\n\n\n\nCode\n1 &lt; 2 \n\n\n[1] TRUE\n\n\nCode\n1 &gt; 2 \n\n\n[1] FALSE\n\n\nCode\n1 &lt;= 2 \n\n\n[1] TRUE\n\n\nCode\n1 == 2\n\n\n[1] FALSE\n\n\nCode\n1 != 2\n\n\n[1] TRUE\n\n\nCode\n1 &gt; 2 \n\n\n[1] FALSE\n\n\nCode\n5 %in% 1:6\n\n\n[1] TRUE\n\n\nCode\n5 %in% 1:4\n\n\n[1] FALSE\n\n\n \n\n\n\n\n3.3.2 Vectorization\nMost functions are vectorized:\n\n\nCode\n1:6 * 1:6\n\n\n\n* Modified from Grolemund & Wickham 2017\n \n\n\n[1]  1  4  9 16 25 36\n\n\n\n\nCode\n1:6 - 1:6\n\n\n[1] 0 0 0 0 0 0\n\n\nR recycles vectors of unequal length:\n\n\nCode\n1:6 * 1:5\n\n\n\n* Modified from Grolemund & Wickham 2017\n\n \n\n3.3.3 Additional package functions\nThese are functions that are included in additional packages that can be installed and loaded into R. To be used the package must be installed and loaded, e.g. to use the corTest function of the “psych” package we must first install. The packages are installed from the CRAN (Comprehensive R Archive Network) server with the install.packages() function:\n\n\nCode\ninstall.packages(\"psych\")\n\n\n… and load the package:\n\n\nCode\nlibrary(psych)\n\n\nOnce ‘psych’ is installed and loaded, we can call the corTest function:\n\n\nCode\ncorTest(iris$Sepal.Length, iris$Sepal.Width)\n\n\nCall:corTest(x = iris$Sepal.Length, y = iris$Sepal.Width)\nCorrelation matrix \n[1] -0.12\nSample Size \n[1] 150\nThese are the unadjusted probability values.\n  The probability values  adjusted for multiple tests are in the p.adj object. \n[1] 0.15\n\n To see confidence intervals of the correlations, print with the short=FALSE option\n\n\nThe use of external packages is the most useful feature of R since it allows to make use of an almost infinite number of specialized functions in different tasks as well as in very diverse fields of science and industry.\nWe can explore the packages available for R at the CRAN website (click on the “packages” link)."
  },
  {
    "objectID": "r_basics.html#exercise-2",
    "href": "r_basics.html#exercise-2",
    "title": "Basic elements of the R language",
    "section": "3.4 Exercise 2",
    "text": "3.4 Exercise 2\n\nSearch for a package you are interested in on CRAN\nInstall the package and load it\nRun the example code of one of its functions"
  },
  {
    "objectID": "r_basics.html#object-manipulation",
    "href": "r_basics.html#object-manipulation",
    "title": "Basic elements of the R language",
    "section": "3.5 Object manipulation",
    "text": "3.5 Object manipulation"
  },
  {
    "objectID": "r_basics.html#extracting-subsets-using-indexing",
    "href": "r_basics.html#extracting-subsets-using-indexing",
    "title": "Basic elements of the R language",
    "section": "3.6 Extracting subsets using indexing",
    "text": "3.6 Extracting subsets using indexing\nElements within objects can be called by indexing. To subset a vector simply call the position of the object using square brackets:\n\n\nCode\nx &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"a\")\n\nx[1]\n\n\n[1] \"a\"\n\n\nCode\nx[2]\n\n\n[1] \"b\"\n\n\nCode\nx[2:3]\n\n\n[1] \"b\" \"c\"\n\n\nCode\nx[c(1,3)]\n\n\n[1] \"a\" \"c\"\n\n\n \nThe elements can be removed in the same way:\n\n\nCode\nx[-1]\n\n\n[1] \"b\" \"c\" \"d\" \"e\" \"a\"\n\n\nCode\nx[-c(1,3)]\n\n\n[1] \"b\" \"d\" \"e\" \"a\"\n\n\n \nThe position of the indices can also be given by a conditional evaluation. For instance, this code selects the elements in x in which the value is “a”:\n\n\nCode\nx[x == \"a\"]\n\n\n[1] \"a\" \"a\"\n\n\nNotice that there are two steps in this process. First we create a logical vector in which TRUE means that the condition is met and FALSE that is not:\n\n\nCode\nis_a &lt;- x == \"a\"\n\nis_a\n\n\n[1]  TRUE FALSE FALSE FALSE FALSE  TRUE\n\n\n.. and then we use it to subset the data frame:\n\n\nCode\nx[is_a]\n\n\n[1] \"a\" \"a\"\n\n\nConditional evaluations can also be used for numeric vectors (e.g. ‘&gt;’, ‘==’) and to subset bidimensional objects based on columns or rows.\nMatrices and data frames require 2 indices [row, column]:\n\n\nCode\nm &lt;- matrix(c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"), nrow = 2)\n\nm[1, ]\n\n\n[1] \"a\" \"c\" \"e\"\n\n\nCode\nm[, 1]\n\n\n[1] \"a\" \"b\"\n\n\nCode\nm[1, 1]\n\n\n[1] \"a\"\n\n\nCode\nm[-1, ]\n\n\n[1] \"b\" \"d\" \"f\"\n\n\nCode\nm[, -1]\n\n\n     [,1] [,2]\n[1,] \"c\"  \"e\" \n[2,] \"d\"  \"f\" \n\n\nCode\nm[-1, -1]\n\n\n[1] \"d\" \"f\"\n\n\nCode\ndf &lt;- data.frame(\n  provincia = c(\"San José\", \"Guanacaste\", \"Guanacaste\"), \n  canton = c(\"Montes de Oca\", \"Nicoya\", \"Liberia\"), \n    distrito = c(\"San Rafael\", \"Nosara\", \"Nacascolo\")\n  )\n\ndf\n\n\n\n\n\n\nprovincia\ncanton\ndistrito\n\n\n\n\nSan José\nMontes de Oca\nSan Rafael\n\n\nGuanacaste\nNicoya\nNosara\n\n\nGuanacaste\nLiberia\nNacascolo\n\n\n\n\n\n\nCode\ndf[1, ]\n\n\n\n\n\n\nprovincia\ncanton\ndistrito\n\n\n\n\nSan José\nMontes de Oca\nSan Rafael\n\n\n\n\n\n\nCode\ndf[, 1]\n\n\n[1] \"San José\"   \"Guanacaste\" \"Guanacaste\"\n\n\nCode\ndf[1, 1]\n\n\n[1] \"San José\"\n\n\nCode\ndf[-1, ]\n\n\n\n\n\n\n\nprovincia\ncanton\ndistrito\n\n\n\n\n2\nGuanacaste\nNicoya\nNosara\n\n\n3\nGuanacaste\nLiberia\nNacascolo\n\n\n\n\n\n\nCode\ndf[, -1]\n\n\n\n\n\n\ncanton\ndistrito\n\n\n\n\nMontes de Oca\nSan Rafael\n\n\nNicoya\nNosara\n\n\nLiberia\nNacascolo\n\n\n\n\n\n\nCode\ndf[-1, -1]\n\n\n\n\n\n\n\ncanton\ndistrito\n\n\n\n\n2\nNicoya\nNosara\n\n\n3\nLiberia\nNacascolo\n\n\n\n\n\n\nData frames can also be subsetted using the name of the columns:\n\n\nCode\ndf[,\"provincia\"]\n\n\n[1] \"San José\"   \"Guanacaste\" \"Guanacaste\"\n\n\nCode\ndf[,c(\"provincia\", \"canton\")]\n\n\n\n\n\n\nprovincia\ncanton\n\n\n\n\nSan José\nMontes de Oca\n\n\nGuanacaste\nNicoya\n\n\nGuanacaste\nLiberia\n\n\n\n\n\n\nCode\ndf$provincia\n\n\n[1] \"San José\"   \"Guanacaste\" \"Guanacaste\"\n\n\n \nLists require 1 index between double square brackets [[index]]:\n\n\nCode\nl &lt;- list(c(\"a\", \"b\"),\n          c(1, 2, 3),\n          c(FALSE, TRUE, FALSE, FALSE))\n\nl[[1]]\n\n\n[1] \"a\" \"b\"\n\n\nCode\nl[[3]]\n\n\n[1] FALSE  TRUE FALSE FALSE\n\n\n \nElements within lists can also be subsets in the same code string:\n\n\nCode\nl[[1]][1:2]\n\n\n[1] \"a\" \"b\"\n\n\nCode\nl[[3]][2]\n\n\n[1] TRUE"
  },
  {
    "objectID": "r_basics.html#explore-objects",
    "href": "r_basics.html#explore-objects",
    "title": "Basic elements of the R language",
    "section": "3.7 Explore objects",
    "text": "3.7 Explore objects\nThe following basic R functions (default) can help us to explore the structure of objects:\n\n\nCode\nstr(df)\n\n\n'data.frame':   3 obs. of  3 variables:\n $ provincia: chr  \"San José\" \"Guanacaste\" \"Guanacaste\"\n $ canton   : chr  \"Montes de Oca\" \"Nicoya\" \"Liberia\"\n $ distrito : chr  \"San Rafael\" \"Nosara\" \"Nacascolo\"\n\n\nCode\nnames(df)\n\n\n[1] \"provincia\" \"canton\"    \"distrito\" \n\n\nCode\ndim(df)\n\n\n[1] 3 3\n\n\nCode\nnrow(df)\n\n\n[1] 3\n\n\nCode\nncol(df)\n\n\n[1] 3\n\n\nCode\nhead(df)\n\n\n\n\n\n\nprovincia\ncanton\ndistrito\n\n\n\n\nSan José\nMontes de Oca\nSan Rafael\n\n\nGuanacaste\nNicoya\nNosara\n\n\nGuanacaste\nLiberia\nNacascolo\n\n\n\n\n\n\nCode\ntail(df)\n\n\n\n\n\n\nprovincia\ncanton\ndistrito\n\n\n\n\nSan José\nMontes de Oca\nSan Rafael\n\n\nGuanacaste\nNicoya\nNosara\n\n\nGuanacaste\nLiberia\nNacascolo\n\n\n\n\n\n\nCode\ntable(df$provincia)\n\n\n\nGuanacaste   San José \n         2          1 \n\n\nCode\nclass(df)\n\n\n[1] \"data.frame\"\n\n\n\n\nCode\nView(df)"
  },
  {
    "objectID": "r_basics.html#exercise-3",
    "href": "r_basics.html#exercise-3",
    "title": "Basic elements of the R language",
    "section": "3.8 Exercise 3",
    "text": "3.8 Exercise 3\n\nUse the example data iris to create a subset of data with only the observations of the species setosa.\nNow create a subset of data containing the observations of both setosa and versicolor.\nAlso with iris create a subset of data with the observations for which iris$Sepal.length is greater than 6\nHow many observations have a sepal length greater than 6?"
  },
  {
    "objectID": "r_basics.html#file-names",
    "href": "r_basics.html#file-names",
    "title": "Basic elements of the R language",
    "section": "4.1 File names",
    "text": "4.1 File names\nFile names must end in .R and, of course, be self-explanatory:\n\nGood: graph_posterior_probability.R\nBad: graf.R"
  },
  {
    "objectID": "r_basics.html#object-names",
    "href": "r_basics.html#object-names",
    "title": "Basic elements of the R language",
    "section": "4.2 Object names",
    "text": "4.2 Object names\nVariables and functions:\n\nLowercase\nUse an underscore\nIn general, names for variables and verbs for functions.\nKeep names concise and meaningful (not always easy).\nAvoid using names of existing functions of variables\n\n\n\nCode\n- GOOD: day_one: day_1, mean_weight(),\n  \n- BAD: dayone, day1, first_day.of.month"
  },
  {
    "objectID": "r_basics.html#syntax",
    "href": "r_basics.html#syntax",
    "title": "Basic elements of the R language",
    "section": "4.3 Syntax",
    "text": "4.3 Syntax\n\n4.3.1 Spaces\n\nUse spaces around operators and for arguments within a function.\nAlways put a space after a comma, and never before (as in normal English).\nPlace a space before the left parenthesis, except in a function call.\n\n\n\nCode\n  - GOOD: \n          a &lt;- rnorm(n = 10, sd = 10, mean = 1)\n          total &lt;- sum(x[1, ])\n\n  - BAD: \n         a&lt;-rnorm(n=10,sd=10,mean=1) \n         total &lt;- sum(x[,1])  \n\n\n \n\n4.3.1.1 Brackets\n\nThe opening key should never go on its own line.\nThe closing brace must always be on its own line.\nYou can omit braces when a block consists of only one statement\n\n\n\nCode\n  - GOOD:\n              if (is.null(ylim)) {\n              ylim &lt;- c(0, 0.06)\n            }\n                      \n            if (is.null(ylim))\n              ylim &lt;- c(0, 0.06)\n          \n  - BAD:\n            \n         if (is.null(ylim)) ylim &lt;- c(0, 0.06)\n                    \n         if (is.null(ylim)) {ylim &lt;- c(0, 0.06)} \n\n         if (is.null(ylim)) {\n           ylim &lt;- c(0, 0.06)\n           } \n\n\n \n\n\n4.3.1.2 Create objects\n\nUse &lt;-, instead of =\n\n\n\nCode\n  - GOOD:\n         x &lt;- 5 \n          \n  - BAD:\n         x = 5\n\n\n \n\n\n4.3.1.3 Suggestions to add comments\n\nComment your code\nEntire commented lines should begin with # and a space.\nShort comments can be placed after the code preceded by two spaces, #, and then a space.\n\n\n\nCode\n# Create histogram of frequency of campaigns by pct budget spent.\nhist(df$pct.spent,\n     breaks = \"scott\",  # method for choosing number of buckets\n     main   = \"Histogram: individuals per unit of time\",\n     xlab   = \"Individual count\",\n     ylab   = \"Frequency\")"
  },
  {
    "objectID": "r_basics.html#package-documentation",
    "href": "r_basics.html#package-documentation",
    "title": "Basic elements of the R language",
    "section": "5.1 Package documentation",
    "text": "5.1 Package documentation"
  },
  {
    "objectID": "r_basics.html#reference-manuals",
    "href": "r_basics.html#reference-manuals",
    "title": "Basic elements of the R language",
    "section": "5.2 Reference manuals",
    "text": "5.2 Reference manuals\nReference manuals are collections of documentation for all the functions of a package (only 1 per package):\n\ndynaSpec manual\nbaRulho manual"
  },
  {
    "objectID": "r_basics.html#documentation-of-functions",
    "href": "r_basics.html#documentation-of-functions",
    "title": "Basic elements of the R language",
    "section": "5.3 Documentation of functions",
    "text": "5.3 Documentation of functions\nAll functions (default or loaded packages) must have documentation that follows a standard format:\n\n\nCode\n?mean\n\nhelp(\"mean\")\n\n\n\nThis documentation can also be displayed in Rstudio by pressing F1 when the cursor is on the function name.\nIf you do not remember the function name try apropos():\n\n\nCode\napropos(\"mean\")\n\n\n [1] \".colMeans\"      \".rowMeans\"      \"circadian.mean\" \"circular.mean\" \n [5] \"colMeans\"       \"geometric.mean\" \"harmonic.mean\"  \"kmeans\"        \n [9] \"mean\"           \"mean.Date\"      \"mean.default\"   \"mean.difftime\" \n[13] \"mean.POSIXct\"   \"mean.POSIXlt\"   \"rowMeans\"       \"weighted.mean\" \n[17] \"winsor.mean\"    \"winsor.means\""
  },
  {
    "objectID": "r_basics.html#vignettes-vignettes",
    "href": "r_basics.html#vignettes-vignettes",
    "title": "Basic elements of the R language",
    "section": "5.4 Vignettes (vignettes)",
    "text": "5.4 Vignettes (vignettes)\nVignettes are illustrative documents or case studies detailing the use of a package (optional, can be several per package).\nVignettes can be called directly from R:\n\n\nCode\nvgn &lt;- browseVignettes() \n\n\n\n\nCode\nvignette()\n\n\nTambién deberían aparecer en la página del paquete en CRAN."
  },
  {
    "objectID": "r_basics.html#exercise-4",
    "href": "r_basics.html#exercise-4",
    "title": "Basic elements of the R language",
    "section": "5.5 Exercise 4",
    "text": "5.5 Exercise 4\n\nWhat does the cut() function do?\nWhat is the breaks argument used for in cut()?\nRun the first 4 lines of code from the examples provided in the cut() documentation.\nHow many bullets does the warbleR package have?"
  },
  {
    "objectID": "r_basics.html#session-info",
    "href": "r_basics.html#session-info",
    "title": "Basic elements of the R language",
    "section": "Session info",
    "text": "Session info\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.2 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: America/Costa_Rica\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] psych_2.3.12\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.5       nlme_3.1-155      svglite_2.1.3     cli_3.6.3        \n [5] knitr_1.48        rlang_1.1.4       xfun_0.47         stringi_1.8.4    \n [9] highr_0.11        jsonlite_1.8.8    glue_1.7.0        colorspace_2.1-1 \n[13] htmltools_0.5.8.1 scales_1.3.0      rmarkdown_2.28    grid_4.3.2       \n[17] evaluate_0.24.0   munsell_0.5.1     kableExtra_1.4.0  fastmap_1.2.0    \n[21] yaml_2.3.10       lifecycle_1.0.4   stringr_1.5.1     compiler_4.3.2   \n[25] htmlwidgets_1.6.4 rstudioapi_0.16.0 lattice_0.20-45   systemfonts_1.1.0\n[29] digest_0.6.37     viridisLite_0.4.2 R6_2.5.1          parallel_4.3.2   \n[33] mnormt_2.1.1      magrittr_2.0.3    tools_4.3.2       xml2_1.3.6"
  },
  {
    "objectID": "importing_data.html",
    "href": "importing_data.html",
    "title": "Importing and formatting data",
    "section": "",
    "text": "Get familiar with the basic input data format\nKnow the main functions to import data and format it"
  },
  {
    "objectID": "importing_data.html#setting-the-working-directory",
    "href": "importing_data.html#setting-the-working-directory",
    "title": "Importing and formatting data",
    "section": "2.1 Setting the working directory",
    "text": "2.1 Setting the working directory\nTo read data in R you need to specify the working directory. It can be set with the function setwd(). The way you do this depends on the operating system (windows, mac, Linux). The folder directory syntax follows the nested structure of the folders. For instance:\n\n\nCode\nsetwd(\"/home/m/Desktop/\")\n\n\n… sets the working directory in the folder “Desktop”, which is found within “m”, which is found within “home”.\n \nSome basic tips for setting the working directory:\n\nThe path to the folder should be quoted (““)\nMake sure you have forward-slash (/) between folder names (although double backward-slashes seem to work on Windows)\nDo not include any file name in the folder directory name\nTo find the location you can look at the properties of a file in that folder and copy it\nThe name matches exactly (better to copy/paste)\nUse list.files() to check which files are in the working directory\nR can suggest and auto-complete the folder names by pressing “tab” when within quotes:\n\n \n\n \n\n2.1.1 Setting the working directory on Windows\nIn windows it should be something like this:\n\n\nCode\nsetwd(\"C:/location\")\n\n\nYou can also do this (only on windows!):\n\n\nCode\nsetwd(choose.dir())\n\n\n  That should pop-up a window where you can choose the location. However, this should only be used to figure out the correct way to write the directory location, not as part of the script itself.\n \n\n\n2.1.2 Setting the working directory in OSX (mac)\nFor mac setting the working directory should be something like this:\n\n\nCode\nsetwd(\"/Users/yourname/..\")\n\n\ndo not include whatever you have before “users” (like macintosh… )\n \n\n\n2.1.3 Setting the working directory in Linux\nSimilar to the code used in OSX:\n\n\nCode\nsetwd(\"/home/m/Desktop/\")\n\n\n \nThe “~” (tilde) can also be used to skip the “home” and “user” folder in Linux:\n\n\nCode\nsetwd(\"~/Desktop/\")\n\n\n \nThe current working directory can be checked as follows:\n\n\nCode\ngetwd()\n\n\n[1] \"/home/marce/Dropbox/courses_and_workshops/estadistica/OTS_TBCP_2024\""
  },
  {
    "objectID": "importing_data.html#reading-data",
    "href": "importing_data.html#reading-data",
    "title": "Importing and formatting data",
    "section": "2.2 Reading data",
    "text": "2.2 Reading data\nAny file can be read in R. It’s just a matter of letting R know in which format is the file encoded (e.g. what conventions were followed when generating the file). The most common formats to store/exchange data sets as the ones we usually handle in biological sciences are txt, csv and xls/xlsx.\n \nThe most commonly used function to import data in R is read.table. The documentation of this function actually includes all the default functions for inputting data:\n\n\nCode\n?read.table\n\n\n \n\n \n\n2.2.1 Reading .txt files\n.txt files can be read using read.table. Let’s first download a freely available data set in .txt format:\n\n\nCode\n# set working directory\nsetwd(\"PUT THE FOLDER LOCATION WHERE YOU WANT TO SAVE THE FILE HERE\")\n\ndownload.file(\n  \"https://raw.githubusercontent.com/maRce10/OTS_TBCP_2024/master/data/pantheria_mammals_data.txt\",\n  destfile = \"pantheria_mammals_data.txt\"\n)\n\n\nYou can also manually download the file from here\n \nThe file can be input into R as follows:\n\n\nCode\n# read file\npntr_dt &lt;- read.table(\"pantheria_mammals_data.txt\",\n                      sep = \"\\t\",\n                      header = TRUE)\n\n\n\n\nCode\n# check structure\nhead(pntr_dt)\n\n\n\n\n\n\n\n\nMSW93_Order\nMSW93_Family\nMSW93_Genus\nMSW93_Species\nMSW93_Binomial\nX1.1_ActivityCycle\nX5.1_AdultBodyMass_g\nX8.1_AdultForearmLen_mm\nX13.1_AdultHeadBodyLen_mm\nX2.1_AgeatEyeOpening_d\nX3.1_AgeatFirstBirth_d\nX18.1_BasalMetRate_mLO2hr\nX5.2_BasalMetRateMass_g\nX6.1_DietBreadth\nX7.1_DispersalAge_d\nX9.1_GestationLen_d\nX12.1_HabitatBreadth\nX22.1_HomeRange_km2\nX22.2_HomeRange_Indiv_km2\nX14.1_InterBirthInterval_d\nX15.1_LitterSize\nX16.1_LittersPerYear\nX17.1_MaxLongevity_m\nX5.3_NeonateBodyMass_g\nX13.2_NeonateHeadBodyLen_mm\nX21.1_PopulationDensity_n.km2\nX10.1_PopulationGrpSize\nX23.1_SexualMaturityAge_d\nX10.2_SocialGrpSize\nX24.1_TeatNumber\nX12.2_Terrestriality\nX6.2_TrophicLevel\nX25.1_WeaningAge_d\nX5.4_WeaningBodyMass_g\nX13.3_WeaningHeadBodyLen_mm\nReferences\nX5.5_AdultBodyMass_g_EXT\nX16.2_LittersPerYear_EXT\nX5.6_NeonateBodyMass_g_EXT\nX5.7_WeaningBodyMass_g_EXT\nX26.1_GR_Area_km2\nX26.2_GR_MaxLat_dd\nX26.3_GR_MinLat_dd\nX26.4_GR_MRLat_dd\nX26.5_GR_MaxLong_dd\nX26.6_GR_MinLong_dd\nX26.7_GR_MRLong_dd\nX27.1_HuPopDen_Min_n.km2\nX27.2_HuPopDen_Mean_n.km2\nX27.3_HuPopDen_5p_n.km2\nX27.4_HuPopDen_Change\nX28.1_Precip_Mean_mm\nX28.2_Temp_Mean_01degC\nX30.1_AET_Mean_mm\nX30.2_PET_Mean_mm\n\n\n\n\nRodentia\nMuridae\nAbditomys\nlatidens\nAbditomys latidens\n-999\n268\n-999.00\n223.99\n-999\n-999\n-999\n-999\n-999\n-999\n-999.00\n-999\n-999\n-999\n-999\n-999.00\n-999\n-999.0\n-999.0\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n2152\n-999\n-999\n-999\n-999\n357\n16.94\n16.74\n16.84\n120.97\n120.78\n120.88\n93\n93.00\n93\n0.09\n316.00\n180.00\n1443.00\n1557.0\n\n\nRodentia\nMuridae\nAbrawayaomys\nruschii\nAbrawayaomys ruschii\n-999\n63\n-999.00\n-999.00\n-999\n-999\n-999\n-999\n-999\n-999\n-999.00\n-999\n-999\n-999\n-999\n-999.00\n-999\n-999.0\n-999.0\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n2655\n-999\n-999\n-999\n-999\n126137\n-15.09\n-19.84\n-17.47\n-40.52\n-43.56\n-42.04\n5\n21.21\n7\n0.06\n107.06\n209.10\n1084.47\n1402.4\n\n\nRodentia\nAbrocomidae\nAbrocoma\nbennettii\nAbrocoma bennettii\n1\n251\n-999.00\n-999.00\n-999\n-999\n-999\n-999\n-999\n-999\n-999.00\n3\n-999\n-999\n-999\n4.86\n-999\n27.6\n-999.0\n-999\n142\n-999\n-999\n-999\n-999\n2\n-999\n-999\n-999\n-999\n543;890;1297;1492;2655\n-999\n-999\n-999\n-999\n54616\n-27.71\n-35.58\n-31.64\n-69.40\n-71.70\n-70.55\n0\n63.15\n1\n0.07\n20.44\n17.66\n213.09\n1073.8\n\n\nRodentia\nAbrocomidae\nAbrocoma\nboliviensis\nAbrocoma boliviensis\n-999\n158\n-999.00\n-999.00\n-999\n-999\n-999\n-999\n-999\n-999\n-999.00\n-999\n-999\n-999\n-999\n-999.00\n-999\n-999.0\n-999.0\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n-999\n2655\n-999\n-999\n-999\n-999\n5774\n-17.44\n-18.05\n-17.75\n-63.49\n-64.51\n-64.00\n5\n29.24\n5\n0.04\n82.63\n175.55\n1171.61\n1487.3\n\n\nRodentia\nAbrocomidae\nAbrocoma\ncinerea\nAbrocoma cinerea\n-999\n194\n-999.00\n-999.00\n-999\n-999\n-999\n-999\n-999\n-999\n109.64\n3\n-999\n-999\n-999\n2.20\n-999\n-999.0\n13.3\n-999\n-999\n-999\n-999\n-999\n-999\n2\n-999\n-999\n-999\n-999\n890;1297;1627;2655\n-999\n-999\n-999\n-999\n381391\n-14.43\n-24.35\n-19.39\n-64.27\n-70.60\n-67.43\n0\n13.72\n0\n0.06\n48.46\n35.22\n515.10\n1257.3\n\n\nChiroptera\nPteropodidae\nAcerodon\ncelebensis\nAcerodon celebensis\n-999\n382\n133.49\n201.55\n-999\n-999\n-999\n-999\n-999\n-999\n-999.00\n1\n-999\n-999\n-999\n0.98\n-999\n-999.0\n-999.0\n-999\n-999\n-999\n-999\n-999\n-999\n2\n-999\n-999\n-999\n-999\n978;1297;1658;2151;2655\n-999\n-999\n-999\n-999\n173613\n3.74\n-6.49\n-1.37\n126.34\n118.75\n122.55\n5\n92.68\n17\n0.07\n229.41\n215.47\n1812.60\n1909.2\n\n\n\n\n\n\n\n\n \nThe file name is quoted and contains the file extension.\n \nNote that the value -999 is used to define empty cells. We can read this values as NAs while importing the data using the ‘na.strings’ argument:\n\n\nCode\n# read file\npntr_dt &lt;- read.table(\"pantheria_mammals_data.txt\", sep = \"\\t\", header = TRUE, na.strings = \"-999\")\n\n# check structure\nhead(pntr_dt)\n\n\n\n\n\n\n\n\nMSW93_Order\nMSW93_Family\nMSW93_Genus\nMSW93_Species\nMSW93_Binomial\nX1.1_ActivityCycle\n\n\n\n\nRodentia\nMuridae\nAbditomys\nlatidens\nAbditomys latidens\nNA\n\n\nRodentia\nMuridae\nAbrawayaomys\nruschii\nAbrawayaomys ruschii\nNA\n\n\nRodentia\nAbrocomidae\nAbrocoma\nbennettii\nAbrocoma bennettii\n1\n\n\nRodentia\nAbrocomidae\nAbrocoma\nboliviensis\nAbrocoma boliviensis\nNA\n\n\nRodentia\nAbrocomidae\nAbrocoma\ncinerea\nAbrocoma cinerea\nNA\n\n\nChiroptera\nPteropodidae\nAcerodon\ncelebensis\nAcerodon celebensis\nNA\n\n\n\n\n\n\n\n\n\n\n\n\nX5.1_AdultBodyMass_g\nX8.1_AdultForearmLen_mm\nX13.1_AdultHeadBodyLen_mm\nX2.1_AgeatEyeOpening_d\n\n\n\n\n268\nNA\n223.99\nNA\n\n\n63\nNA\nNA\nNA\n\n\n251\nNA\nNA\nNA\n\n\n158\nNA\nNA\nNA\n\n\n194\nNA\nNA\nNA\n\n\n382\n133.49\n201.55\nNA\n\n\n\n\n\n\n\n\n \n\n\n2.2.2 Reading .csv files\nAgain, we can download an example file online and read it:\n\n\nCode\ndownload.file(\"https://github.com/maRce10/OTS_TBCP_2024/raw/master/data/clements_bird_list.csv\", destfile = \"clements_bird_list.csv\")\n\n\nclm_lst &lt;- read.csv(\"clements_bird_list.csv\")\n\nhead(clm_lst)\n\n\n\n\n\n\n\n\nTAXON_ORDER\nCATEGORY\nSPECIES_CODE\nPRIMARY_COM_NAME\nSCI_NAME\nORDER1\nFAMILY\nSPECIES_GROUP\nREPORT_AS\n\n\n\n\n3\nspecies\nostric2\nCommon Ostrich\nStruthio camelus\nStruthioniformes\nStruthionidae (Ostriches)\nOstriches\n\n\n\n5\nspecies\nostric3\nSomali Ostrich\nStruthio molybdophanes\nStruthioniformes\nStruthionidae (Ostriches)\n\n\n\n\n6\nslash\ny00934\nCommon/Somali Ostrich\nStruthio camelus/molybdophanes\nStruthioniformes\nStruthionidae (Ostriches)\n\n\n\n\n7\nspecies\ngrerhe1\nGreater Rhea\nRhea americana\nRheiformes\nRheidae (Rheas)\nRheas\n\n\n\n13\nspecies\nlesrhe2\nLesser Rhea\nRhea pennata\nRheiformes\nRheidae (Rheas)\n\n\n\n\n14\nissf\nlesrhe4\nLesser Rhea (Puna)\nRhea pennata tarapacensis/garleppi\nRheiformes\nRheidae (Rheas)\n\nlesrhe2\n\n\n\n\n\n\n\n\nYou can also manually download the file from here (Note that the name of the downloaded file might differ to that in this tutorial).\nAs in the previous example, we can tell R how to identify empty cells using the ‘na.strings’ argument:\n\n\nCode\nclm_lst &lt;- read.csv(\"clements_bird_list.csv\", na.strings = \"\")\n\nhead(clm_lst)\n\n\n\n\n\n\n\n\nTAXON_ORDER\nCATEGORY\nSPECIES_CODE\nPRIMARY_COM_NAME\nSCI_NAME\nORDER1\nFAMILY\nSPECIES_GROUP\nREPORT_AS\n\n\n\n\n3\nspecies\nostric2\nCommon Ostrich\nStruthio camelus\nStruthioniformes\nStruthionidae (Ostriches)\nOstriches\nNA\n\n\n5\nspecies\nostric3\nSomali Ostrich\nStruthio molybdophanes\nStruthioniformes\nStruthionidae (Ostriches)\nNA\nNA\n\n\n6\nslash\ny00934\nCommon/Somali Ostrich\nStruthio camelus/molybdophanes\nStruthioniformes\nStruthionidae (Ostriches)\nNA\nNA\n\n\n7\nspecies\ngrerhe1\nGreater Rhea\nRhea americana\nRheiformes\nRheidae (Rheas)\nRheas\nNA\n\n\n13\nspecies\nlesrhe2\nLesser Rhea\nRhea pennata\nRheiformes\nRheidae (Rheas)\nNA\nNA\n\n\n14\nissf\nlesrhe4\nLesser Rhea (Puna)\nRhea pennata tarapacensis/garleppi\nRheiformes\nRheidae (Rheas)\nNA\nlesrhe2\n\n\n\n\n\n\n\n\n\n\n2.2.3 Reading excel files\nMost researchers enter data into excel spreadsheets. So it would be pretty handy to read the data directly from there. To read xls and xlsx files we need to install the package “readxl” (there are other packages that can be used but they all work similarly):\n\n\nCode\ninstall.packages(pkgs = \"readxl\")\n\n\n \nAnd load it:\n\n\nCode\nlibrary(readxl)\n\n\n \nAs we did above, download an example file from an online repository. In this case is the same Clements bird taxonomy list in xlsx format:\n\n\nCode\ndownload.file(\"https://github.com/maRce10/OTS_TBCP_2024/raw/master/data/clements_bird_list.xlsx\", destfile = \"clements_bird_list.xlsx\")\n\n\nYou can also manually download the file from here\n \nNow we can use the function read_excel() to read the file:\n\n\nCode\n# read file\nclm_lst2 &lt;- read_excel(\"clements_bird_list.xlsx\", sheet = 1)\n\nhead(clm_lst2)\n\n\n\n\n\n\n\n\nTAXON_ORDER\nCATEGORY\nSPECIES_CODE\nPRIMARY_COM_NAME\nSCI_NAME\n\n\n\n\n3\nspecies\nostric2\nCommon Ostrich\nStruthio camelus\n\n\n5\nspecies\nostric3\nSomali Ostrich\nStruthio molybdophanes\n\n\n6\nslash\ny00934\nCommon/Somali Ostrich\nStruthio camelus/molybdophanes\n\n\n7\nspecies\ngrerhe1\nGreater Rhea\nRhea americana\n\n\n13\nspecies\nlesrhe2\nLesser Rhea\nRhea pennata\n\n\n14\nissf\nlesrhe4\nLesser Rhea (Puna)\nRhea pennata tarapacensis/garleppi\n\n\n\n\n\n\n\n\n\n\n\n\nORDER1\nFAMILY\nSPECIES_GROUP\nREPORT_AS\n\n\n\n\nStruthioniformes\nStruthionidae (Ostriches)\nOstriches\nNA\n\n\nStruthioniformes\nStruthionidae (Ostriches)\nNA\nNA\n\n\nStruthioniformes\nStruthionidae (Ostriches)\nNA\nNA\n\n\nRheiformes\nRheidae (Rheas)\nRheas\nNA\n\n\nRheiformes\nRheidae (Rheas)\nNA\nNA\n\n\nRheiformes\nRheidae (Rheas)\nNA\nlesrhe2\n\n\n\n\n\n\n\n\n \nYou need to specify the file name (including extension) and the excel sheet (tab) name. read_excel() auto detects the format from the file extension. The functions read_xls() and read_xlsx() can be used to read files without extension.\n \n\n\n2.2.4 Exercise 1\nAll default functions to input data into R have a counterpart to export the same type of data. The names of these other functions are similar to the ones for reading data, although they typically start with “write” or “save”.\n\nWhat are the names of the default functions for exporting the data formats we used above? (hint: try apropos to check which functions are available)\nExport the mammals data as a .csv file\nExport the mammals data again, this time excluding the row names\nRead the .csv file using read.table\nWhat other packages can import excel files into R?\nCan you export an excel file or add data to an existing excel file from R?\nUsing the “clements_bird_list.csv” file, how would you tell R to read both “Rheiformes” and “Ostriches” as empty cells (while still reading empty cells as empty cells)?"
  },
  {
    "objectID": "importing_data.html#reading-excel-files",
    "href": "importing_data.html#reading-excel-files",
    "title": "Importing and formatting data",
    "section": "2.3 Reading excel files",
    "text": "2.3 Reading excel files\nMost researchers enter data into excel spreadsheets. So it would be pretty handy to read the data directly from there. To read xls and xlsx files we need to install the package “readxl” (there are other packages that can be used but they all work similarly):\n\n\nCode\ninstall.packages(pkgs = \"readxl\")\n\n\n \nAnd load it:\n\n\nCode\nlibrary(readxl)\n\n\n \nAs we did above, download an example file from an online repository. In this case is the same Clements bird taxonomy list in xlsx format:\n\n\nCode\ndownload.file(\"https://github.com/maRce10/OTS_TBCP_2024/raw/master/data/clements_bird_list.xlsx\", destfile = \"clements_bird_list.xlsx\")\n\n\nYou can also manually download the file from here\n \nNow we can use the function read_excel() to read the file:\n\n\nCode\n# read file\nclm_lst2 &lt;- read_excel(\"clements_bird_list.xlsx\", sheet = 1)\n\nhead(clm_lst2)\n\n\n\n\n\n\n\n\nTAXON_ORDER\nCATEGORY\nSPECIES_CODE\nPRIMARY_COM_NAME\nSCI_NAME\n\n\n\n\n3\nspecies\nostric2\nCommon Ostrich\nStruthio camelus\n\n\n5\nspecies\nostric3\nSomali Ostrich\nStruthio molybdophanes\n\n\n6\nslash\ny00934\nCommon/Somali Ostrich\nStruthio camelus/molybdophanes\n\n\n7\nspecies\ngrerhe1\nGreater Rhea\nRhea americana\n\n\n13\nspecies\nlesrhe2\nLesser Rhea\nRhea pennata\n\n\n14\nissf\nlesrhe4\nLesser Rhea (Puna)\nRhea pennata tarapacensis/garleppi\n\n\n\n\n\n\n\n\n\n\n\n\nORDER1\nFAMILY\nSPECIES_GROUP\nREPORT_AS\n\n\n\n\nStruthioniformes\nStruthionidae (Ostriches)\nOstriches\nNA\n\n\nStruthioniformes\nStruthionidae (Ostriches)\nNA\nNA\n\n\nStruthioniformes\nStruthionidae (Ostriches)\nNA\nNA\n\n\nRheiformes\nRheidae (Rheas)\nRheas\nNA\n\n\nRheiformes\nRheidae (Rheas)\nNA\nNA\n\n\nRheiformes\nRheidae (Rheas)\nNA\nlesrhe2\n\n\n\n\n\n\n\n\n \nYou need to specify the file name (including extension) and the excel sheet (tab) name. read_excel() auto detects the format from the file extension. The functions read_xls() and read_xlsx() can be used to read files without extension.\n \n\n2.3.1 Exercise 1\nAll default functions to input data into R have a counterpart to export the same type of data. The names of these other functions are similar to the ones for reading data, although they typically start with “write” or “save”.\n1.1 What are the names of the default functions for exporting the data formats we used above? (hint: try apropos to check which functions are available)\n1.2 Export the mammals data as a .csv file\n1.3 Export the mammals data again, this time excluding the row names\n1.4 Read the .csv file using read.table\n1.5 What other packages can import excel files into R?\n1.6 Can you export an excel file or add data to an existing excel file from R?\n1.7 Using the “clements_bird_list.csv” file, how would you tell R to read both “Rheiformes” and “Ostriches” as empty cells (while still reading empty cells as empty cells)?"
  },
  {
    "objectID": "importing_data.html#tidy-data",
    "href": "importing_data.html#tidy-data",
    "title": "Importing and formatting data",
    "section": "3.1 Tidy data",
    "text": "3.1 Tidy data\n“Tidy data” is a logic for organizing data sets in a consistent and intuitive way. To run some of the code below you will need the ‘tidyr’ and ‘dplyr’ packages, which can be installed/loaded as follows:\n\n\nCode\ninstall.packages(pkgs = \"tidyr\")\n\ninstall.packages(pkgs = \"dplyr\")\n\nlibrary(tidyr)\n\nlibrary(dplyr)\n\n\n \nThe same data can be represented in many ways. In the example below each data set shows exactly the same values of four variables country, year, population, and cases, but in each data set values are organized in a different way. The data shows the number of tuberculosis cases in Afghanistan, Brazil, and China between 1999 and 2000:\n\n\nCode\nas.data.frame(table1)\n\n\n\n\n\n\n\n\ncountry\nyear\ncases\npopulation\n\n\n\n\nAfghanistan\n1999\n745\n19987071\n\n\nAfghanistan\n2000\n2666\n20595360\n\n\nBrazil\n1999\n37737\n172006362\n\n\nBrazil\n2000\n80488\n174504898\n\n\nChina\n1999\n212258\n1272915272\n\n\nChina\n2000\n213766\n1280428583\n\n\n\n\n\n\n\n\n\n\nCode\nas.data.frame(table2)\n\n\n\n\n\n\n\n\ncountry\nyear\ntype\ncount\n\n\n\n\nAfghanistan\n1999\ncases\n745\n\n\nAfghanistan\n1999\npopulation\n19987071\n\n\nAfghanistan\n2000\ncases\n2666\n\n\nAfghanistan\n2000\npopulation\n20595360\n\n\nBrazil\n1999\ncases\n37737\n\n\nBrazil\n1999\npopulation\n172006362\n\n\nBrazil\n2000\ncases\n80488\n\n\nBrazil\n2000\npopulation\n174504898\n\n\nChina\n1999\ncases\n212258\n\n\nChina\n1999\npopulation\n1272915272\n\n\nChina\n2000\ncases\n213766\n\n\nChina\n2000\npopulation\n1280428583\n\n\n\n\n\n\n\n\n\n\nCode\nas.data.frame(table3)\n\n\n\n\n\n\n\n\ncountry\nyear\nrate\n\n\n\n\nAfghanistan\n1999\n745/19987071\n\n\nAfghanistan\n2000\n2666/20595360\n\n\nBrazil\n1999\n37737/172006362\n\n\nBrazil\n2000\n80488/174504898\n\n\nChina\n1999\n212258/1272915272\n\n\nChina\n2000\n213766/1280428583\n\n\n\n\n\n\n\n\nOr even spread across 2 different data sets:\n\n\nCode\nas.data.frame(table4a)\n\n\n\n\n\n\n\n\ncountry\n1999\n2000\n\n\n\n\nAfghanistan\n745\n2666\n\n\nBrazil\n37737\n80488\n\n\nChina\n212258\n213766\n\n\n\n\n\n\n\n\n\n\nCode\nas.data.frame(table4b)\n\n\n\n\n\n\n\n\ncountry\n1999\n2000\n\n\n\n\nAfghanistan\n19987071\n20595360\n\n\nBrazil\n172006362\n174504898\n\n\nChina\n1272915272\n1280428583\n\n\n\n\n\n\n\n\n \nAll these data sets contained the same underlying data. However, they are not equally easy to use.\nThere are three interrelated rules to make a data set tidy:\n\nEach variable must have its own column\nEach observation must have its own row\nEach value must have its own cell\n\nThis figure shows the rules visually:\n * Modified from R for Data Science  \nThese three rules are interrelated because it’s impossible to only satisfy two of the three. That interrelationship leads to an even simpler set of practical instructions:\n\nPut each data set in a data frame\nPut each variable in a column\n\n \nIn the example above, only table1 is tidy. It’s the only representation where each column is a variable. There are two main advantages of formatting the data in this way:\n\nIf you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity\nPlacing variables in columns fits well R’s vectorized nature. As we have seen, built-in R functions work with vectors of values. That makes transforming tidy data feel particularly natural\n\n \n\nExercise 2\n\n2.1 Describe how the variables and observations are organized in each of the sample data frames\n\n2.2 Calculate the rate of cases per 10000 people for “table1”, “table2” and “table4a”/“table4b”"
  },
  {
    "objectID": "importing_data.html#gathering-data",
    "href": "importing_data.html#gathering-data",
    "title": "Importing and formatting data",
    "section": "3.2 Gathering data",
    "text": "3.2 Gathering data\nA common problem is a data set where some of the column names are not names of variables, but values of a variable. Take “table4a”: the column names 1999 and 2000 represent values of the year variable, and each row represents two observations, not one:\n\n\nCode\nas.data.frame(table4a)\n\n\n\n\n\n\n\n\ncountry\n1999\n2000\n\n\n\n\nAfghanistan\n745\n2666\n\n\nBrazil\n37737\n80488\n\n\nChina\n212258\n213766\n\n\n\n\n\n\n\n\n \nTo tidy a data set like this, we need to gather those columns into a new pair of variables. To do this we need three parameters:\n\nThe set of columns that represent values, not variables. In this example, those are the columns 1999 and 2000\nThe name of the variable whose values form the column names. In the ‘tidyr’ syntax that is called the key, which in this case is year\nThe name of the variable whose values are spread over the cells. In the ‘tidyr’ syntax that is called that value, which in this case is the number of cases\n\nThese parameters can be used to create a tidy data set using the function gather():\n\n\nCode\ngather(table4a, key = \"year\", value = \"cases\", `1999`, `2000`)\n\n\n\n\n\n\n\n\ncountry\nyear\ncases\n\n\n\n\nAfghanistan\n1999\n745\n\n\nBrazil\n1999\n37737\n\n\nChina\n1999\n212258\n\n\nAfghanistan\n2000\n2666\n\n\nBrazil\n2000\n80488\n\n\nChina\n2000\n213766\n\n\n\n\n\n\n\n\nWe can visualize this formatting as follows:\n * Modified from R for Data Science  \ngather() can also be used to tidy table4b. The only difference is the variable stored in the cell values:\n\n\nCode\ngather(data = table4b, key = \"year\", value = \"population\", `1999`, `2000`)\n\n\n\n\n\n\n\n\ncountry\nyear\npopulation\n\n\n\n\nAfghanistan\n1999\n19987071\n\n\nBrazil\n1999\n172006362\n\n\nChina\n1999\n1272915272\n\n\nAfghanistan\n2000\n20595360\n\n\nBrazil\n2000\n174504898\n\n\nChina\n2000\n1280428583\n\n\n\n\n\n\n\n\n \nTo combine the tidied versions of table4a and table4b into a single data frame (or ‘tibble’), we can either use dplyr::left_join() or merge() from base R:\n\n\nCode\ntidy4a &lt;- gather(table4a, key = \"year\", value = \"cases\", `1999`, `2000`)\n\ntidy4b &lt;- gather(table4b, key = \"year\", value = \"population\", `1999`, `2000`)\n\nleft_join(x = tidy4a, y = tidy4b, by = c(\"country\", \"year\"))\n\n\n\n\n\n\n\n\ncountry\nyear\ncases\npopulation\n\n\n\n\nAfghanistan\n1999\n745\n19987071\n\n\nBrazil\n1999\n37737\n172006362\n\n\nChina\n1999\n212258\n1272915272\n\n\nAfghanistan\n2000\n2666\n20595360\n\n\nBrazil\n2000\n80488\n174504898\n\n\nChina\n2000\n213766\n1280428583\n\n\n\n\n\n\n\n\n\n\nCode\nmerge(x = tidy4a, y =  tidy4b, by = c(\"country\", \"year\"))\n\n\n\n\n\n\n\n\ncountry\nyear\ncases\npopulation\n\n\n\n\nAfghanistan\n1999\n745\n19987071\n\n\nAfghanistan\n2000\n2666\n20595360\n\n\nBrazil\n1999\n37737\n172006362\n\n\nBrazil\n2000\n80488\n174504898\n\n\nChina\n1999\n212258\n1272915272\n\n\nChina\n2000\n213766\n1280428583"
  },
  {
    "objectID": "importing_data.html#spreading",
    "href": "importing_data.html#spreading",
    "title": "Importing and formatting data",
    "section": "3.3 Spreading",
    "text": "3.3 Spreading\nSpreading is the opposite of gathering. You use it when an observation is scattered across multiple rows. For example, in table2 an observation is a country in a year, but each observation is spread across two rows:\n\n\nCode\ntable2\n\n\n\n\n\n\n\n\ncountry\nyear\ntype\ncount\n\n\n\n\nAfghanistan\n1999\ncases\n745\n\n\nAfghanistan\n1999\npopulation\n19987071\n\n\nAfghanistan\n2000\ncases\n2666\n\n\nAfghanistan\n2000\npopulation\n20595360\n\n\nBrazil\n1999\ncases\n37737\n\n\nBrazil\n1999\npopulation\n172006362\n\n\nBrazil\n2000\ncases\n80488\n\n\nBrazil\n2000\npopulation\n174504898\n\n\nChina\n1999\ncases\n212258\n\n\nChina\n1999\npopulation\n1272915272\n\n\nChina\n2000\ncases\n213766\n\n\nChina\n2000\npopulation\n1280428583\n\n\n\n\n\n\n\n\n \nTo tidy this data set up, we only need two parameters:\n\nThe column that contains variable names, the key column. Here, it’s type.\nThe column that contains values forms multiple variables, the value column. Here it’s count.\n\n \nTo do this we can use spread():\n\n\nCode\nspread(table2, key = \"type\", value = \"count\")\n\n\n\n\n\n\n\n\ncountry\nyear\ncases\npopulation\n\n\n\n\nAfghanistan\n1999\n745\n19987071\n\n\nAfghanistan\n2000\n2666\n20595360\n\n\nBrazil\n1999\n37737\n172006362\n\n\nBrazil\n2000\n80488\n174504898\n\n\nChina\n1999\n212258\n1272915272\n\n\nChina\n2000\n213766\n1280428583\n\n\n\n\n\n\n\n\n \nwhich can be visualized as follows:\n * Modified from R for Data Science  \nspread() and gather() are complementary functions. gather() makes wide tables narrower and longer; spread() makes long tables shorter and wider.\n \n\nExercise 3\n\n3.1 Tidy up the following data set on tree height for 2 species:\n\n\nCode\nplnt_sz &lt;- data.frame(forest = c(\"old_growth\", \"disturbed\"), \n                      Species_1 = c(154, 160), \n                      Species_2 = c(120, 113))\n\n\n\n \n\nSeparating and uniting\nSo far we have fixed “table2” and “table4”, but not “table3”. “table3” has a different problem: we have one column (rate) that contains two variables (cases and population*). This can be fixed using the separate() function . We will also look at its complementunite(), which is used when a single variable is spread across multiple columns."
  },
  {
    "objectID": "importing_data.html#separate",
    "href": "importing_data.html#separate",
    "title": "Importing and formatting data",
    "section": "3.4 Separate",
    "text": "3.4 Separate\nseparate() pulls apart one column into multiple columns, by splitting wherever a separator character appears. Take table3:\n\n\nCode\nas.data.frame(table3)\n\n\n\n\n\n\n\n\ncountry\nyear\nrate\n\n\n\n\nAfghanistan\n1999\n745/19987071\n\n\nAfghanistan\n2000\n2666/20595360\n\n\nBrazil\n1999\n37737/172006362\n\n\nBrazil\n2000\n80488/174504898\n\n\nChina\n1999\n212258/1272915272\n\n\nChina\n2000\n213766/1280428583\n\n\n\n\n\n\n\n\nVisually it does something like this:\n * Modified from R for Data Science\n \nThe rate column contains both cases and population variables, and we need to split it into two variables. separate() takes the name of the column to separate, and the names of the new columns to be created:\n\n\nCode\nseparate(data = table3, col =  rate, into = c(\"cases\", \"population\"))\n\n\n\n\n\n\n\n\ncountry\nyear\ncases\npopulation\n\n\n\n\nAfghanistan\n1999\n745\n19987071\n\n\nAfghanistan\n2000\n2666\n20595360\n\n\nBrazil\n1999\n37737\n172006362\n\n\nBrazil\n2000\n80488\n174504898\n\n\nChina\n1999\n212258\n1272915272\n\n\nChina\n2000\n213766\n1280428583\n\n\n\n\n\n\n\n\nBy default, separate() will split based on any non-alphanumeric character (i.e. a character that isn’t a number or letter). In the code above, separate() split the values of rate at the forward slash characters. This can be explicitly stated (to avoid any errors):\n\n\nCode\ntb3 &lt;- separate(data = table3, col = rate,  into = c(\"cases\", \"population\"), sep = \"/\")\n\ntb3 \n\n\n\n\n\n\n\n\ncountry\nyear\ncases\npopulation\n\n\n\n\nAfghanistan\n1999\n745\n19987071\n\n\nAfghanistan\n2000\n2666\n20595360\n\n\nBrazil\n1999\n37737\n172006362\n\n\nBrazil\n2000\n80488\n174504898\n\n\nChina\n1999\n212258\n1272915272\n\n\nChina\n2000\n213766\n1280428583\n\n\n\n\n\n\n\n\ntibble [6 × 4] (S3: tbl_df/tbl/data.frame)\n $ country   : chr [1:6] \"Afghanistan\" \"Afghanistan\" \"Brazil\" \"Brazil\" ...\n $ year      : num [1:6] 1999 2000 1999 2000 1999 ...\n $ cases     : chr [1:6] \"745\" \"2666\" \"37737\" \"80488\" ...\n $ population: chr [1:6] \"19987071\" \"20595360\" \"172006362\" \"174504898\" ...\n\n\n \nNote that the case and population are character columns. By default separate() leaves the type of the new columns as in the original one. In this case this is not ideal as those really are numbers. We can ask separate() to try and convert to better types using convert = TRUE:\n\n\nCode\ntb3 &lt;- separate(data = table3, col = rate, into = c(\"cases\", \"population\"), convert = TRUE)\n\nstr(tb3)\n\n\ntibble [6 × 4] (S3: tbl_df/tbl/data.frame)\n $ country   : chr [1:6] \"Afghanistan\" \"Afghanistan\" \"Brazil\" \"Brazil\" ...\n $ year      : num [1:6] 1999 2000 1999 2000 1999 ...\n $ cases     : int [1:6] 745 2666 37737 80488 212258 213766\n $ population: int [1:6] 19987071 20595360 172006362 174504898 1272915272 1280428583\n\n\n \nYou can also pass a vector of integers to sep, which will be interpreted as positions to split at. Positive values start at 1 on the far-left of the strings; negative value start at -1 on the far-right of the strings. When using integers to separate strings, the length of sep should be one less than the number of names in into. You can use this to separate the last two digits of each year:\n\n\nCode\nseparate(data = table3, col = year, into = c(\"century\", \"year\"), \n         sep = 2)\n\n\n\n\n\n\n\n\ncountry\ncentury\nyear\nrate\n\n\n\n\nAfghanistan\n19\n99\n745/19987071\n\n\nAfghanistan\n20\n00\n2666/20595360\n\n\nBrazil\n19\n99\n37737/172006362\n\n\nBrazil\n20\n00\n80488/174504898\n\n\nChina\n19\n99\n212258/1272915272\n\n\nChina\n20\n00\n213766/1280428583\n\n\n\n\n\n\n\n\nSeparating columns can also be done with base R, although it takes a bit more coding:\n\n\nCode\ntable3$cases &lt;- sapply(table3$rate, function(x) try(strsplit(x, \"/\")[[1]][1]), USE.NAMES = FALSE)\n\ntable3$population &lt;- sapply(table3$rate, function(x) try(strsplit(x, \"/\")[[1]][2]), USE.NAMES = FALSE)\n\ntb3 \n\n\n\n\n\n\n\n\ncountry\nyear\nrate\ncases\npopulation\n\n\n\n\nAfghanistan\n1999\n745/19987071\n745\n19987071\n\n\nAfghanistan\n2000\n2666/20595360\n2666\n20595360\n\n\nBrazil\n1999\n37737/172006362\n37737\n172006362\n\n\nBrazil\n2000\n80488/174504898\n80488\n174504898\n\n\nChina\n1999\n212258/1272915272\n212258\n1272915272\n\n\nChina\n2000\n213766/1280428583\n213766\n1280428583\n\n\n\n\n\n\n\n\ntibble [6 × 4] (S3: tbl_df/tbl/data.frame)\n $ country   : chr [1:6] \"Afghanistan\" \"Afghanistan\" \"Brazil\" \"Brazil\" ...\n $ year      : num [1:6] 1999 2000 1999 2000 1999 ...\n $ cases     : chr [1:6] \"745\" \"2666\" \"37737\" \"80488\" ...\n $ population: chr [1:6] \"19987071\" \"20595360\" \"172006362\" \"174504898\" ..."
  },
  {
    "objectID": "importing_data.html#unite",
    "href": "importing_data.html#unite",
    "title": "Importing and formatting data",
    "section": "3.5 Unite",
    "text": "3.5 Unite\nunite() is the inverse of separate(): combining multiple columns into a single column:\n * Modified from R for Data Science\n \nHowever, you will need it much less frequently than separate().\nWe can use unite() to rejoin the century and year columns that we created above:\n\n\nCode\nunite(data = table5, col = \"new\", \"century\", \"year\")\n\n\n\n\n\n\n\n\ncountry\nnew\nrate\n\n\n\n\nAfghanistan\n19_99\n745/19987071\n\n\nAfghanistan\n20_00\n2666/20595360\n\n\nBrazil\n19_99\n37737/172006362\n\n\nBrazil\n20_00\n80488/174504898\n\n\nChina\n19_99\n212258/1272915272\n\n\nChina\n20_00\n213766/1280428583\n\n\n\n\n\n\n\n\nIn this function we can also use the sep argument (although in this example it was not specified).\n \n\nExercise 3\n\n3.1 Unite century and year in “table5” using base R (hint: paste())"
  },
  {
    "objectID": "course_prep.html",
    "href": "course_prep.html",
    "title": "OTS TBCP 2024",
    "section": "",
    "text": "Install R on the computer you will use during the course https://cran.r-project.org/. I assume that you already have it installed, but try to update it if you have an R version &lt; 4.0.0. You can find which R version you have by running this in the R console:\n\n\n\nCode\nversion$version.string\n\n\n\nInstall the RStudio interface (https://www.rstudio.com/products/rstudio/download/, choose the free version). Optional but advised.\nOpen RStudio and select the tab “Tools” then “Global Options” (last option). Select the “Code” option, then select the box for “Soft-wrap R source files”.\nAlso in Rstudio: Select the “Pane Layout” option and move “Source” to the top left pane and “Console” to the top right pane. For those of you unfamiliar with RStudio, the source is your script, where you save code in a physical file (usually .R script) and the console prints the output of the code you run from the source. You can write code in the console, but it will not be saved in a physical file. This layout allocates more screen space to the most useful panes. Hit “Apply” and “Ok”.\nNow in the R console in Rstudio run the following code to install the packages that will be used during the workshop:\n\n\n\nCode\ninstall.packages(c(\"ggplot2\",\n                 \"lme4\",\n                 \"MASS\",\n                 \"viridis\",\n                 \"lmerTest\",\n                 \"car\",\n                 \"sjstats\",\n                 \"sjPlot\"))\n\n\n \n\nA few tips to ensure you will take full advantage of the course:\n \n\nSet aside a physical space, hopefully as isolated as possible from external stimuli\nUse headphones/earphones to avoid distractions from echoes or external noises\nMake sure you have everything you need before the start of the class\nBe ready a few minutes before the start of the class\nTry to focus as much as possible on the course, close other programs or unnecessary internet browser tabs (i.e. instagram, twitter, etc). This will also make your computer more efficient (less likely to slow down)\nComment your code"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OTS TBCP 2024",
    "section": "",
    "text": "Stats Workshop\n\n\nOrganization For Tropical Studies\n\n\n\nMarcelo Araya-Salas, PhD\n\n\n\nSeptember, 2024\n\n\n\n\nTraditionally, statistical models have been taught as disconnected tools with no clear relationship between them. However, most of those common statistical models are just special cases of linear models. Hence, learning them as such can simplify things substantially. The course will focus on linear regression as the main tool for statistical inference. Students will be introduced to the basic elements of a linear regression model, its interpretation, as well as hands-on experience on building those models in R.\n\nObjetives\n\nUse R as the main tool for stats\nUnderstand statistical inference through a single modelling tool (broad sense linear models)\nGet familiar with building linear models\nExtend linear models to different data structures"
  },
  {
    "objectID": "instructor.html",
    "href": "instructor.html",
    "title": "OTS TBCP 2024",
    "section": "",
    "text": "Marcelo Araya-Salas\n\n\n\n\n\nI am just another behavioral ecologists that ended up doing a lot of coding just to get data analysis done. So now I’m deeply involved in the development of computational tools for (non-genetic) biological data analysis, mostly related to animal behavior and bioacoustics. I am the developer and maintainer of the R packages warbleR and Rraven that provide functions to streamline high-throughput acoustic analysis of animal sounds, aiming to simplify the use of R for bioacoustic research. More recently I released the R packages baRulho, to quantify acoustic signal transmission and degradation, ohun, to optimize automatic detection and PhenotypeSpace for quantifying multidimensional trait spaces. Also check out the new R package sketchy for organizing research compendiums. New functions as well as other more elaborated analyses are detailed in my blog Bioacoustics in R."
  },
  {
    "objectID": "simulate_data.html",
    "href": "simulate_data.html",
    "title": "Simulating data in R",
    "section": "",
    "text": "Get familiar with the basic random generating functions in R\nUse simulated data to understand the behavior of statistical tools\nPlease load the following packages:\nCode\nlibrary(ggplot2)\nlibrary(viridis)"
  },
  {
    "objectID": "simulate_data.html#generating-categorical-variables",
    "href": "simulate_data.html#generating-categorical-variables",
    "title": "Simulating data in R",
    "section": "1.1 Generating categorical variables",
    "text": "1.1 Generating categorical variables\nThe easiest way to generate categorical variables is to use the ‘letters’ (or ‘LETTERS’) example vector to assign category levels. We can do this using the function rep(). For instance, the following code creates a categorical (character) vector with two levels, each one with 4 observations:\n\n\nCode\nrep(x = letters[1:2], each = 4)\n\n\n[1] \"a\" \"a\" \"a\" \"a\" \"b\" \"b\" \"b\" \"b\"\n\n\n \nWe can also replicate this pattern using the argument ‘times’. This code replicates the previous vector 2 times:\n\n\nCode\nrep(x = letters[1:2], each = 4, times = 2)\n\n\n [1] \"a\" \"a\" \"a\" \"a\" \"b\" \"b\" \"b\" \"b\" \"a\" \"a\" \"a\" \"a\" \"b\" \"b\" \"b\" \"b\"\n\n\n \nAnother option is to simulate a variable from a binomial distribution and then convert it into a factor:\n\n\nCode\n# run rbinom\nbinom_var &lt;- rbinom(n = 50, size = 1, prob = 0.5)\n\nbinom_var\n\n\n [1] 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0\n[39] 1 1 0 0 0 0 0 1 0 1 1 1\n\n\n\n\nCode\ncateg_var &lt;- factor(binom_var, labels = c(\"a\",\n    \"b\"))\n\ncateg_var\n\n\n [1] b a a b b a a a a a a a b b b a a b a b a a a a a a a b a b b b a a a b a a\n[39] b b a a a a a b a b b b\nLevels: a b"
  },
  {
    "objectID": "simulate_data.html#random-sampling",
    "href": "simulate_data.html#random-sampling",
    "title": "Simulating data in R",
    "section": "1.2 Random sampling",
    "text": "1.2 Random sampling\nThe other important R tool for playing with simulated data is sample(). This function allows you to take samples of specific sizes from vectors. For instance, take the example vector letters:\n\n\nCode\nletters\n\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n\n \nWe can take a sample of this vector like is:\n\n\nCode\nsample(x = letters, size = 10)\n\n\n [1] \"i\" \"r\" \"q\" \"a\" \"c\" \"m\" \"y\" \"z\" \"u\" \"v\"\n\n\n \nThe argument ‘size’ allow us to determine the size of the sample. Note that we get an error if the size is larger than the vector itself:\n\n\nCode\nsample(x = letters, size = 30)\n\n\nError in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'\n\n\n \nThis can only be done when sampling with replacement. Sampling with replacement can be applied by setting the argument replace = TRUE:\n\n\nCode\nsample(x = letters, size = 30, replace = TRUE)\n\n\n [1] \"j\" \"i\" \"h\" \"i\" \"k\" \"u\" \"n\" \"i\" \"w\" \"k\" \"c\" \"t\" \"m\" \"p\" \"i\" \"h\" \"d\" \"w\" \"c\"\n[20] \"q\" \"j\" \"e\" \"e\" \"j\" \"k\" \"c\" \"l\" \"t\" \"r\" \"h\""
  },
  {
    "objectID": "simulate_data.html#iterating-a-process",
    "href": "simulate_data.html#iterating-a-process",
    "title": "Simulating data in R",
    "section": "1.3 Iterating a process",
    "text": "1.3 Iterating a process\nOften simulations most be repeated several times to rule out spurious results due to chance or just to try different parameters. The functions for simulating data mentioned above can be run several times (e.g. iterated) using the function replicate():\n\n\nCode\nrepl_rnorm &lt;- replicate(n = 3, expr = rnorm(2),\n    simplify = FALSE)\n\nclass(repl_rnorm)\n\n\n[1] \"list\"\n\n\nCode\nrepl_rnorm\n\n\n[[1]]\n[1]  1.19184 -0.33992\n\n[[2]]\n[1]  0.78911 -0.63213\n\n[[3]]\n[1] -1.49312 -0.13441"
  },
  {
    "objectID": "simulate_data.html#making-simulations-reproducible",
    "href": "simulate_data.html#making-simulations-reproducible",
    "title": "Simulating data in R",
    "section": "1.4 Making simulations reproducible",
    "text": "1.4 Making simulations reproducible\nThe last trick we need to run simulations in R is the ability to reproduce a simulation (i.e. get the exact same simulated data and results). This can be useful for allowing other researchers to run our analyses in the exact same way. This can be easily done with the function set.seed(). Try running the following code. You should get the same output:\n\n\nCode\nset.seed(10)\n\nrunif(n = 2)\n\n\n[1] 0.50748 0.30677"
  },
  {
    "objectID": "simulate_data.html#datasets-with-numeric-and-categorical-data",
    "href": "simulate_data.html#datasets-with-numeric-and-categorical-data",
    "title": "Simulating data in R",
    "section": "2.1 Datasets with numeric and categorical data",
    "text": "2.1 Datasets with numeric and categorical data\nNow that we know how to simulate continuous and categorical variable. We can put them together to create simulated data sets. This can be done using the function data.frame():\n\n\nCode\n# create categorical variable\ngroup &lt;- rep(x = letters[1:2], each = 3)\n\n# create continous data\nsize &lt;- rnorm(n = 6, mean = 5, sd = 1)\n\n# put them together in a data frame\ndf &lt;- data.frame(group, size)\n\n# print\ndf\n\n\n\n\n\n\ngroup\nsize\n\n\n\n\na\n4.8157\n\n\na\n3.6287\n\n\na\n4.4008\n\n\nb\n5.2945\n\n\nb\n5.3898\n\n\nb\n3.7919\n\n\n\n\n\n\nOf course, we could add more variables to this data frame:\n\n\nCode\n# create categorical variable\ngroup &lt;- rep(x = letters[1:2], each = 3)\nindividual &lt;- LETTERS[1:6]\n\n# create continous data\nsize &lt;- rnorm(n = 6, mean = 5, sd = 1)\nweight &lt;- rnorm(n = 6, mean = 100, sd = 10)\n\n\n# put them together in a data frame\ndf &lt;- data.frame(group, individual, size,\n    weight)\n\n# print\ndf\n\n\n\n\n\n\ngroup\nindividual\nsize\nweight\n\n\n\n\na\nA\n4.6363\n109.874\n\n\na\nB\n3.3733\n107.414\n\n\na\nC\n4.7435\n100.894\n\n\nb\nD\n6.1018\n90.451\n\n\nb\nE\n5.7558\n98.049\n\n\nb\nF\n4.7618\n109.255\n\n\n\n\n\n\nAnd that’s a simulated data set in its most basic form. That looks a lot like the kind of data we use to work with in the biological science."
  },
  {
    "objectID": "simulate_data.html#a-proof-of-concept-the-central-limit-theorem",
    "href": "simulate_data.html#a-proof-of-concept-the-central-limit-theorem",
    "title": "Simulating data in R",
    "section": "3.1 A proof of concept: the Central Limit Theorem",
    "text": "3.1 A proof of concept: the Central Limit Theorem\nThe Central Limit Theorem states that, if we take repeated random samples of a population:\n\nThe means of those samples will conform to a normal distribution, even if the population is not normally distributed\nThe resulting normal distribution must have a mean close to the population’s mean\n\nThe theorem is a key concept for inferential statistics as it implies that statistical methods that work for normal distributions can be applicable to many other scenarios in which the original population follow other types of distributions. Nonetheless, the point here is only to showcase how simulations can be used to understand the behavior statistical methods.\nTo check if those basic claims about the Central Limit Theorem hold true we can use simulated data in R. Let’s simulate a 1000 observation population with a uniform distribution:\n\n\nCode\n# simulate uniform population\nunif_pop &lt;- runif(n = 1000, min = 0, max = 10)\n\n# check distribution/ plot histogram\nggplot(data = data.frame(unif_pop), mapping = aes(x = unif_pop)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n \nWe can take random samples using sample() like this:\n\n\nCode\nsample(x = unif_pop, size = 30)\n\n\n [1] 9.28420 1.02626 2.57517 3.32485 6.89990 2.29404 0.33737 8.21366 3.30364\n[10] 8.03793 2.59174 7.81770 5.65426 0.63831 2.83470 4.20434 4.76330 4.42193\n[19] 6.97830 7.92625 0.68121 3.52323 6.51103 5.38289 7.97210 1.80062 4.21282\n[28] 3.33866 8.91223 4.71163\n\n\n \nThis process can be replicated several times with replicate():\n\n\nCode\nsamples &lt;- replicate(n = 100, expr = mean(sample(x = unif_pop,\n    size = 30)))\n\n\n \nThe code above takes 100 samples with 30 values each. We can now check the distribution of the samples:\n\n\nCode\n# check distribution/ plot histogram\nggplot(data = data.frame(samples), mapping = aes(x = samples)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n \n… as well as the mean:\n\n\nCode\nmean(samples)\n\n\n[1] 5.0212\n\n\n \nAs expected, the samples follows a normal distribution with a mean close to the mean of the population, which is:\n\n\nCode\nmean(unif_pop)\n\n\n[1] 5.0527\n\n\n \nLet’s try with a more complex distribution. For instance, a bimodal distribution:\n\n\nCode\n# set seed\nset.seed(123)\n\n# simulate variables\nnorm1 &lt;- rnorm(n = 1000, mean = 10, sd = 3)\nnorm2 &lt;- rnorm(n = 1000, mean = 20, sd = 3)\n\n# add them in a single one\nbimod_pop &lt;- c(norm1, norm2)\n\n# check distribution/ plot histogram\nggplot(data = data.frame(bimod_pop), mapping = aes(x = bimod_pop)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsamples &lt;- replicate(200, mean(sample(bimod_pop,\n    10)))\n\n# check distribution/ plot histogram\nggplot(data = data.frame(samples), mapping = aes(x = samples)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmean(samples)\n\n\n[1] 15.231\n\n\nCode\nmean(bimod_pop)\n\n\n[1] 15.088\n\n\n \n\nExercise\n \n\nTry exploring the Central Limit Theorem as above but this time using:\n\nAn exponential distribution (rexp())\nA binomial distribution (rbinom())\n\n\n \n\nFor each distribution: plot a histogram and compare the means of the population and the samples"
  },
  {
    "objectID": "simulate_data.html#references",
    "href": "simulate_data.html#references",
    "title": "Simulating data in R",
    "section": "References",
    "text": "References\n\nR’s rbinom – Simulate Binomial or Bernoulli trials\nR’s rnorm – selecting values from a normal distribution\nR’s exp – Simulating Exponential Distributions\nSimulating data in R"
  },
  {
    "objectID": "linear_regression.html",
    "href": "linear_regression.html",
    "title": "Linear regression models",
    "section": "",
    "text": "Understand statistical inference through a single modelling tool (broad sense linear models)\nGet familiar with building linear models\nExtent linear models to different data structures"
  },
  {
    "objectID": "linear_regression.html#response-intercept-only-model",
    "href": "linear_regression.html#response-intercept-only-model",
    "title": "Linear regression models",
    "section": "3.1 Response (intercept)-only model",
    "text": "3.1 Response (intercept)-only model\nLet’s first create a response numeric variable:\n\n\nCode\n# set seed\nset.seed(123)\n\n# number of observations\nn &lt;- 50\n\n# random variables\ny &lt;- rnorm(n = n, mean = 0, sd = 1)\n\n# put it in a data frame\ny_data &lt;- data.frame(y)\n\n\nThis single variable can be input in an intercept-only regression model. To do this we need to supply the model formula and the data to lm():\n\n\nCode\n# run model\ny_mod &lt;- lm(formula = y ~ 1, data = y_data)\n\n\nWhich is equivalent to:\n\\(\\hat{Y} \\sim \\beta_{o}\\)\nWe can get the default summary of the model results by running summary() on the output object ‘y_mod’:\n\n\nCode\nsummary(y_mod)\n\n\n\nCall:\nlm(formula = y ~ 1, data = y_data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.001 -0.594 -0.107  0.664  2.135 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   0.0344     0.1309    0.26     0.79\n\nResidual standard error: 0.926 on 49 degrees of freedom\n\n\nIt can be quite informative to plot the effect sizes (although in this case we just have one):\n\n\nCode\nci_df &lt;- data.frame(param = names(y_mod$coefficients),\n    est = y_mod$coefficients, confint(y_mod))\n\nggplot(ci_df, aes(x = param, y = est)) +\n    geom_hline(yintercept = 0, color = \"red\",\n        lty = 2) + geom_pointrange(aes(ymin = X2.5..,\n    ymax = X97.5..)) + labs(x = \"Parameter\",\n    y = \"Effect size\") + coord_flip()\n\n\n\n\n\n\n\n\n\n\nModel interpretation\nFor assessing the significance of the association we focus on the coefficients table:\n\n\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) 0.034404    0.13094 0.26275  0.79385\n\n\n\nIn this example there are no predictors in the model so we only got an estimate for the intercept (\\(\\beta_0\\))\nThe model tell us that the intercept is estimated at 0.0344 and that this value is not significantly different from 0 (p-value = 0.79385)\nIn this case the intercept is simply the mean of the response variable\n\n\n\nCode\nmean(y_data$y)\n\n\n[1] 0.034404\n\n\n\nWe seldom have predictions about the intercept so we tend to ignore this estimate.\n\n\n\nCase study\n\nRuhs, E. C., Martin, L. B., & Downs, C. J. (2020). The impacts of body mass on immune cell concentrations in birds. Proceedings of the Royal Society B, 287(1934), 20200655.\n\n“We found that an intercept-only model best explained lymphocyte and eosinophil concentrations in birds, indicating that concentrations of these cell types were independent of body mass.”\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\nChange the mean argument in the rnorm() function call to a value other than 0 and look at how things change in the coefficients table\nChange the sd argument in the rnorm() function call to a higher value and look at how things change in the coefficients table"
  },
  {
    "objectID": "linear_regression.html#adding-a-non-associated-predictor",
    "href": "linear_regression.html#adding-a-non-associated-predictor",
    "title": "Linear regression models",
    "section": "3.2 Adding a non-associated predictor",
    "text": "3.2 Adding a non-associated predictor\nWe can create 2 unrelated numeric variables like this:\n\n\nCode\n# set seed\nset.seed(123)\n\n# number of observations\nn &lt;- 50\n\n# random variables\ny &lt;- rnorm(n = n, mean = 0, sd = 1)\nx1 &lt;- rnorm(n = n, mean = 0, sd = 1)\n\n# create data frame\nxy_data &lt;- data.frame(x1, y)\n\n\nThese two variables can be input in a regression model to evaluate the association between them:\n\n\nCode\n# build model\nxy_mod &lt;- lm(formula = y ~ x1, data = xy_data)\n\n# plot\nggplot(xy_data, aes(x = x1, y = y)) + geom_smooth(method = \"lm\",\n    se = FALSE) + geom_point()  # plot points\n\n\n\n\n\n\n\n\n\nWhich is equivalent to:\n\\(\\hat{Y} \\sim \\beta_{o} + \\beta_{1} * x_{1}\\)\nLet’s print the summary for this model:\n\n\nCode\nsummary(xy_mod)\n\n\n\nCall:\nlm(formula = y ~ x1, data = xy_data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.004 -0.624 -0.123  0.687  2.106 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   0.0398     0.1340    0.30     0.77\nx1           -0.0367     0.1475   -0.25     0.80\n\nResidual standard error: 0.935 on 48 degrees of freedom\nMultiple R-squared:  0.00129,   Adjusted R-squared:  -0.0195 \nF-statistic: 0.0618 on 1 and 48 DF,  p-value: 0.805\n\n\n… and plot the effect sizes:\n\n\nCode\nci_df &lt;- data.frame(param = names(xy_mod$coefficients),\n    est = xy_mod$coefficients, confint(xy_mod))\n\nggplot(ci_df, aes(x = param, y = est)) +\n    geom_hline(yintercept = 0, color = \"red\",\n        lty = 2) + geom_pointrange(aes(ymin = X2.5..,\n    ymax = X97.5..)) + labs(x = \"Parameter\",\n    y = \"Effect size\") + coord_flip()\n\n\n\n\n\n\n\n\n\nWe should ‘diagnose’ the adequacy of the model by inspecting more closely the distribution of residuals.The function plot_model() from the package ‘sjPlot’ does a good job for creating diagnostic plots for linear models:\n\n\nCode\nplot_model(xy_mod, type = \"diag\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\nModel interpretation\nCoefficients table:\n\n\n             Estimate Std. Error  t value Pr(&gt;|t|)\n(Intercept)  0.039774    0.13396  0.29690  0.76782\nx1          -0.036679    0.14750 -0.24867  0.80467\n\n\n\nIn this example we added one predictor to the model so we got an additional estimate (and extra row, ‘x1’)\nThe model tell us that the estimate of ‘x1’ is -0.03668 and that it is not significantly different from 0 (p-value = 0.80467)"
  },
  {
    "objectID": "linear_regression.html#simulating-an-associated-predictor",
    "href": "linear_regression.html#simulating-an-associated-predictor",
    "title": "Linear regression models",
    "section": "3.3 Simulating an associated predictor",
    "text": "3.3 Simulating an associated predictor\nWe can use the linear model formula above to simulate two associated continuous variables like this:\n\n\nCode\n# set seed\nset.seed(123)\n\n# number of observations\nn &lt;- 50\nb0 &lt;- -4\nb1 &lt;- 3\nerror &lt;- rnorm(n = n, sd = 3)\n\n# random variables\nx1 &lt;- rnorm(n = n, mean = 0, sd = 1)\ny &lt;- b0 + b1 * x1 + error\n\n# create data frame\nxy_data2 &lt;- data.frame(x1, y)\n\n\nNote that we also added an error term, so the association is not perfect. Let’s run the model and plot the association between the two variables:\n\n\nCode\n# build model\nxy_mod2 &lt;- lm(formula = y ~ x1, data = xy_data2)\n\n# plot\nggplot(xy_data2, aes(x = x1, y = y)) + geom_smooth(method = \"lm\",\n    se = FALSE) + geom_point()  # plot points\n\n\n\n\n\n\n\n\n\nThe formula is the same than the previous model:\n\\(\\hat{Y} \\sim \\beta_{o} + \\beta_{1} * x_{1}\\)\nThis is the summary of the model:\n\n\nCode\nsummary(xy_mod2)\n\n\n\nCall:\nlm(formula = y ~ x1, data = xy_data2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6.01  -1.87  -0.37   2.06   6.32 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -3.881      0.402   -9.66  7.9e-13 ***\nx1             2.890      0.442    6.53  3.9e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.8 on 48 degrees of freedom\nMultiple R-squared:  0.471, Adjusted R-squared:  0.459 \nF-statistic: 42.7 on 1 and 48 DF,  p-value: 3.85e-08\n\n\n.. the effect size plot:\n\n\nCode\nci_df &lt;- data.frame(param = names(xy_mod2$coefficients),\n    est = xy_mod2$coefficients, confint(xy_mod2))\n\nggplot(ci_df, aes(x = param, y = est)) +\n    geom_hline(yintercept = 0, color = \"red\",\n        lty = 2) + geom_pointrange(aes(ymin = X2.5..,\n    ymax = X97.5..)) + labs(x = \"Parameter\",\n    y = \"Effect size\") + coord_flip()\n\n\n\n\n\n\n\n\n\n… and the model diagnostic plots:\n\n\nCode\nplot_model(xy_mod2, type = \"diag\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\nModel interpretation\nCoefficients table:\n\n\n            Estimate Std. Error t value   Pr(&gt;|t|)\n(Intercept)  -3.8807    0.40188 -9.6562 7.8616e-13\nx1            2.8900    0.44249  6.5311 3.8537e-08\n\n\n\nThe model tells us that \\(\\beta_1\\) (the effect size of ‘x1’) is 2.88996 and that it is significantly different from 0 (p-value = 3.85365^{-8})\nThe simulated values for the regression parameters can be compared to the summary of the lm() model to get a sense of the model precision:\n\n\\(\\beta_1\\) (the effect size of ‘x1’) was set to 3 and was estimated as 2.89 by the model\n\n\n\n\nCase study\n\nKeenan EL, Odom KJ, Araya-Salas M, Horton KG, Strimas-Mackey M, Meatte MA, Mann NI, Slater PJ, Price JJ, and Templeton CN. 2020. Breeding season length predicts duet coordination and consistency in Neotropical wrens (Troglodytidae). Proceeding of the Royal Society B. 20202482\n\n\n\n\n\n\n\n\n\n\n“… coordination and consistency of duets are greater in species with particularly long mating seasons.”\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\nIncrease the sample size (n) to 1000 or higher\nHow did the effect size (\\(\\beta\\)) estimates change?\nHow did the standard error of the effect size change?\nNow change n to 15 and check again the model estimates (this time check the p-value as well)"
  },
  {
    "objectID": "linear_regression.html#adding-more-than-1-predictor-multiple-regression",
    "href": "linear_regression.html#adding-more-than-1-predictor-multiple-regression",
    "title": "Linear regression models",
    "section": "3.4 Adding more than 1 predictor: multiple regression",
    "text": "3.4 Adding more than 1 predictor: multiple regression\nMultiple linear regression is an extension of the simple linear regression model that can take several predictors:\n\\(\\hat{Y} \\sim \\beta_{o} + \\beta_{1} * x_{1} + \\cdots + \\beta_{n} * x_{n}\\)\nThe formula looks a bit busy, but it only means that any additional parameter will have its own estimate (\\(\\beta\\)). The formula for a two-predictor linear regression looks like this:\n\\(\\hat{Y} \\sim \\beta_{o} + \\beta_{1} * x_{1} + \\beta_{2} * x_{2}\\)\n.. and it can be simulated like this:\n\n\nCode\n# set seed\nset.seed(123)\n\n# number of observations\nn &lt;- 50\nb0 &lt;- -4\nb1 &lt;- 3\nb2 &lt;- -2\nerror &lt;- rnorm(n = n, mean = 0, sd = 3)\n\n# random variables\nx1 &lt;- rnorm(n = n, mean = 0, sd = 1)\nx2 &lt;- rnorm(n = n, mean = 0, sd = 1)\ny &lt;- b0 + b1 * x1 + b2 * x2 + error\n\n# create data frame\nxy_data_multp &lt;- data.frame(x1, x2, y)\n\n# build model\nxy_mod_multp &lt;- lm(formula = y ~ x1 + x2,\n    data = xy_data_multp)\n\nsummary(xy_mod_multp)\n\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = xy_data_multp)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.986 -1.893 -0.363  2.002  6.413 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -3.865      0.417   -9.27  3.5e-12 ***\nx1             2.901      0.453    6.41  6.4e-08 ***\nx2            -1.932      0.414   -4.67  2.6e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.83 on 47 degrees of freedom\nMultiple R-squared:  0.612, Adjusted R-squared:  0.595 \nF-statistic:   37 on 2 and 47 DF,  p-value: 2.23e-10\n\n\n… plot the effect sizes:\n\n\nCode\nci_df &lt;- data.frame(param = names(xy_mod_multp$coefficients),\n    est = xy_mod_multp$coefficients, confint(xy_mod_multp))\n\nggplot(ci_df, aes(x = param, y = est)) +\n    geom_hline(yintercept = 0, color = \"red\",\n        lty = 2) + geom_pointrange(aes(ymin = X2.5..,\n    ymax = X97.5..)) + labs(x = \"Parameter\",\n    y = \"Effect size\") + coord_flip()\n\n\n\n\n\n\n\n\n\n… and the model diagnostic plots:\n\n\nCode\nplot_model(xy_mod_multp, type = \"diag\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\nModel interpretation\nCoefficients table:\n\n\n            Estimate Std. Error t value   Pr(&gt;|t|)\n(Intercept)  -3.8652    0.41695 -9.2702 3.4856e-12\nx1            2.9015    0.45260  6.4108 6.4137e-08\nx2           -1.9324    0.41422 -4.6650 2.5851e-05\n\n\n\nThe model found that \\(\\beta_1\\) (the effect size of ‘x1’) is 2.9015 and that it is significantly different from 0 (p-value = 6.41368^{-8})\nIt also found that the \\(\\beta_2\\) (the effect size of ‘x2’) is -1.93235 and that it is also significantly different from 0 (p-value = 2.58513^{-5})\nThe simulated values for the regression parameters can be compared to the summary of the lm() model to get a sense of the model precision:\n\n\\(\\beta_1\\) was set to 3 and was estimated as 2.901\n\\(\\beta_2\\) (the effect size of ‘x2’) was set to -2 and was estimated as -1.932\n\n\n\n\nCase study\n\nAraya-Salas M, P González-Gómez, K Wojczulanis-Jakubas, V López III & T Wright. 2018. Spatial memory is as important as weapon and body size for territorial ownership in a lekking hummingbird. Scientific Reports. 13, e0189969\n\n“Spatial memory, body size and beak tip length … positively predicted the probability of acquiring and defending a territory.”\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\nSet one of the effect sizes (\\(\\beta\\)) to 0 (or very close to 0) and run again the model and its summary\nHow did the p-value change?\nSimulate a scenario with three predictors in which only one of them is associated with the response\n\n\nThere is an important point to stress here: Multiple regression estimate the effect of a predictor after accounting for the effect of the other predictors in the model. In other words, new predictors in the model will attempt to explain variation in the data that was not explained by the other predictors. So the result of the multiple regression is not equivalent to the results of simple linear regressions on the same predictors. This can be easily shown by running those regressions:\n\n\nCode\n# build models\nx1y_mod &lt;- lm(formula = y ~ x1, data = xy_data)\nx2y_mod &lt;- lm(formula = y ~ x2, data = xy_data)\n\n# shortcut to coefficients\ncoef(xy_mod)\n\n\n(Intercept)          x1 \n   0.039774   -0.036679 \n\n\nCode\ncoef(x1y_mod)\n\n\n(Intercept)          x1 \n   0.039774   -0.036679 \n\n\nCode\ncoef(x2y_mod)\n\n\n(Intercept)          x2 \n   0.041320    0.027239 \n\n\nThe estimates for the same variables vary considerably between the multiple regression and the single predictor regressions.\nThis point is further demonstrated by the fact that, if one of the predictors has no influence at all on the response, the effect of the additional predictor will converge to its effect in a simple linear regression. To simulate this scenario we set b2 to 0:\n\n\nCode\n# set seed\nset.seed(123)\n\n# number of observations\nn &lt;- 50\nb0 &lt;- -4\nb1 &lt;- 3\nb2 &lt;- 0\nerror &lt;- rnorm(n = n, mean = 0, sd = 1)\n\n# random variables\nx1 &lt;- rnorm(n = n, mean = 0, sd = 1)\nx2 &lt;- rnorm(n = n, mean = 0, sd = 1)\ny &lt;- b0 + b1 * x1 + b2 * x2 + error\n\n# create data frame\nxy_data &lt;- data.frame(x1, x2, y)\n\n# build model\nxy_mod &lt;- lm(formula = y ~ x1 + x2, data = xy_data)\nx1y_mod &lt;- lm(formula = y ~ x1, data = xy_data)\n\n# shortcut to coefficients\ncoef(xy_mod)\n\n\n(Intercept)          x1          x2 \n  -3.955064    2.967166    0.022549 \n\n\nCode\ncoef(x1y_mod)\n\n\n(Intercept)          x1 \n    -3.9602      2.9633 \n\n\nThe estimate for \\(\\beta_1\\) was almost the same in the multiple regression (2.96717) and the single predictor regression (2.96332)\nFor convenience we used coef() to extract only the estimates from the regression, but the values are the same we get with summary(model)."
  },
  {
    "objectID": "linear_regression.html#having-a-categorical-predictor",
    "href": "linear_regression.html#having-a-categorical-predictor",
    "title": "Linear regression models",
    "section": "3.5 Having a categorical predictor",
    "text": "3.5 Having a categorical predictor\nFor categorical predictors we can first create a binary (0, 1) variable and then add labels to each value:\n\n\nCode\n# set seed\nset.seed(13)\n\n# number of observations\nn &lt;- 50\nb0 &lt;- -3\nb1 &lt;- 2\nerror &lt;- rnorm(n = n, mean = 0, sd = 3)\n\n# random variables\nx1_num &lt;- sample(0:1, size = n, replace = TRUE)\ny &lt;- b0 + b1 * x1_num + error\n\nx1 &lt;- factor(x1_num, labels = c(\"a\", \"b\"))\n\n# create data frame\nxy_data_cat &lt;- data.frame(x1, x1_num, y)\n\nhead(xy_data_cat)\n\n\n\n\n\n\nx1\nx1_num\ny\n\n\n\n\nb\n1\n0.6630\n\n\na\n0\n-3.8408\n\n\na\n0\n2.3255\n\n\nb\n1\n-0.4380\n\n\na\n0\n0.4276\n\n\na\n0\n-1.7534\n\n\n\n\n\n\nAnd this is how it is formally written:\n\\(\\hat{Y} \\sim \\beta_{o} + \\beta_{1} * x_{1}\\)\nSame thing as with continuous predictors.\nWe can explore the pattern in the data using a boxplot:\n\n\nCode\n# plot\nggplot(xy_data_cat, aes(x = x1, y = y)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n… and get the estimates of the model:\n\n\nCode\n# build model\nxy_mod_cat &lt;- lm(formula = y ~ x1, data = xy_data_cat)\n\nsummary(xy_mod_cat)\n\n\n\nCall:\nlm(formula = y ~ x1, data = xy_data_cat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.898 -1.909 -0.094  1.809  5.506 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -2.997      0.558   -5.37  2.3e-06 ***\nx1b            1.814      0.842    2.16    0.036 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.95 on 48 degrees of freedom\nMultiple R-squared:  0.0882,    Adjusted R-squared:  0.0693 \nF-statistic: 4.65 on 1 and 48 DF,  p-value: 0.0362\n\n\n… plot the effect sizes:\n\n\nCode\nci_df &lt;- data.frame(param = names(xy_mod_cat$coefficients),\n    est = xy_mod_cat$coefficients, confint(xy_mod_cat))\n\nggplot(ci_df, aes(x = param, y = est)) +\n    geom_hline(yintercept = 0, color = \"red\",\n        lty = 2) + geom_pointrange(aes(ymin = X2.5..,\n    ymax = X97.5..)) + labs(x = \"Parameter\",\n    y = \"Effect size\") + coord_flip()\n\n\n\n\n\n\n\n\n\n… and the model diagnostic plots:\n\n\nCode\nplot_model(xy_mod_cat, type = \"diag\")[[2]]\n\n\n\n\n\n\n\n\n\n\nModel interpretation\nCoefficients table:\n\n\n            Estimate Std. Error t value   Pr(&gt;|t|)\n(Intercept)  -2.9974    0.55825 -5.3693 2.2677e-06\nx1b           1.8140    0.84160  2.1554 3.6172e-02\n\n\n\nThe model found that \\(\\beta_1\\) (the effect size of ‘x1’) is 1.814 and that it is significantly different from 0 (p-value = 0.03617)\nThe simulated values for the regression parameters can be compared to the summary of the lm() model to get a sense of the model precision:\n\n\\(\\beta_1\\) was set to 2 and was estimated as 1.814\n\nNote that in this case the intercept refers to the estimate for the level ‘a’ in the categorical predictor, which was used as a baseline:\n\n\n\nCode\n# plot\nggplot(xy_data_cat, aes(x = x1, y = y)) +\n    geom_boxplot() + geom_hline(yintercept = xy_mod_cat$coefficients[1],\n    col = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\n\nHence the intercept is the same as the mean of y for the category ‘a’:\n\n\n\nCode\nmean(xy_data_cat$y[xy_data_cat$x1 == \"a\"])\n\n\n[1] -2.9974\n\n\n\nNote also that the estimate label is ‘x1b’, not ‘x1’ as in the continuous predictors. This is because in this case the estimate refers to the difference between the two levels of the categorical variable (‘a’ and ‘b’). More specifically, it tells us that in average observations from category ‘b’ are 1.814 higher than observations in category ‘a’.\n\n\n\nCase study\n\nRico-Guevara A, & M Araya-Salas. 2015. Bills as daggers? A test for sexually dimorphic weapons in a lekking hummingbird species. Behavioral Ecology. 26 (1): 21-29.\n\n“Males with larger, more pointed beak tips were more successful in gaining control of territories in the lek.”\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\nUnbalanced data when having categories (i.e. some categories have way more observations than others) can be problematic for statistical inference. Modify the code above to simulate a highly unbalanced data set and check the precision of the model.\n\n\n\n\nDummy coding\nIn a regression model categorical predictors are also represented as numeric vectors. More precisely, categorical predictors are coded as 0s and 1s, in which 1 means ‘belongs to the same category’ and 0 ‘belongs to a different category’. We kept the original numeric vector (‘x1_num’) when simulating the data set with the categorical predictor:\n\n\nCode\nhead(xy_data_cat)\n\n\n\n\n\n\nx1\nx1_num\ny\n\n\n\n\nb\n1\n0.6630\n\n\na\n0\n-3.8408\n\n\na\n0\n2.3255\n\n\nb\n1\n-0.4380\n\n\na\n0\n0.4276\n\n\na\n0\n-1.7534\n\n\n\n\n\n\nNote that ‘b’s in the ’x1’ column are converted into 1 in the ‘x1_num’ column and ’a’s converted into 0. This is called an indicator variable and the process is known as dummy coding.\nWe can actually use the numeric vector in the regression model and get the exact same results:\n\n\nCode\n# summary model with categorical\n# variable\nsummary(xy_mod_cat)$coefficients\n\n\n            Estimate Std. Error t value   Pr(&gt;|t|)\n(Intercept)  -2.9974    0.55825 -5.3693 2.2677e-06\nx1b           1.8140    0.84160  2.1554 3.6172e-02\n\n\nCode\n# build model with dummy variable\nxy_mod_num &lt;- lm(formula = y ~ x1_num, data = xy_data_cat)\n\n# summary with dummy coding\nsummary(xy_mod_num)$coefficients\n\n\n            Estimate Std. Error t value   Pr(&gt;|t|)\n(Intercept)  -2.9974    0.55825 -5.3693 2.2677e-06\nx1_num        1.8140    0.84160  2.1554 3.6172e-02\n\n\nThings get a bit more complicated when dummy coding a categorical predictor with more than two levels. But the logic is the same."
  },
  {
    "objectID": "linear_regression.html#interaction-terms",
    "href": "linear_regression.html#interaction-terms",
    "title": "Linear regression models",
    "section": "3.6 Interaction terms",
    "text": "3.6 Interaction terms\nA statistical interaction refers to an effect of a response variable that is mediated by a second variable.\n\\(\\hat{Y} \\sim \\beta_{o} + \\beta_{1} * x_{1} + \\beta_{2} * x_{2} + \\beta_{3} * x_{1} * x_{2}\\)\nThis is easier to understand by looking at the interaction of a continuous and a binary variable:\n\n\nCode\n# set seed\nset.seed(123)\n\n# number of observations\nn &lt;- 50\nb0 &lt;- -4\nb1 &lt;- 3\nb2 &lt;- 1.7\nb3 &lt;- -3\nerror &lt;- rnorm(n = n, mean = 0, sd = 3)\n\n# random variables\nx1 &lt;- rbinom(n = n, size = 1, prob = 0.5)\nx2 &lt;- rnorm(n = n, mean = 0, sd = 1)\n\n# interaction is added as the product\n# of x1 and x2\ny &lt;- b0 + b1 * x1 + b2 * x2 + b3 * x1 * x2 +\n    error\n\nx1 &lt;- factor(x1, labels = c(\"a\", \"b\"))\n\n# create data frame\nxy_data_intr &lt;- data.frame(x1, x2, y)\n\nhead(xy_data_intr)\n\n\n\n\n\n\nx1\nx2\ny\n\n\n\n\nb\n1.0256\n-4.0147\n\n\na\n-0.2848\n-5.1746\n\n\na\n-1.2207\n-1.3991\n\n\nb\n0.1813\n-1.0242\n\n\na\n-0.1389\n-3.8483\n\n\nb\n0.0058\n4.1377\n\n\n\n\n\n\nCode\n# build model\nxy_mod_intr &lt;- lm(formula = y ~ x1 + x2 +\n    x1 * x2, data = xy_data_intr)\n\n# save summary to make best fit lines\nxy_summ_intr &lt;- summary(xy_mod_intr)\n\nxy_summ_intr\n\n\n\nCall:\nlm(formula = y ~ x1 + x2 + x1 * x2, data = xy_data_intr)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.222 -1.664 -0.158  1.650  6.383 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -4.193      0.570   -7.35  2.7e-09 ***\nx1b            3.597      0.806    4.46  5.2e-05 ***\nx2             1.327      0.682    1.95   0.0576 .  \nx1b:x2        -2.972      0.962   -3.09   0.0034 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.83 on 46 degrees of freedom\nMultiple R-squared:  0.396, Adjusted R-squared:  0.357 \nF-statistic:   10 on 3 and 46 DF,  p-value: 3.29e-05\n\n\nIt also helps to plot the data (don’t worry too much about all the code):\n\n\nCode\n# plot\nggplot(data = xy_data_intr, aes(x = x2, y = y,\n    color = x1)) + geom_point(size = 3) +\n    geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n… and the effect sizes:\n\n\nCode\nci_df &lt;- data.frame(param = names(xy_mod_intr$coefficients),\n    est = xy_mod_intr$coefficients, confint(xy_mod_intr))\n\nggplot(ci_df, aes(x = param, y = est)) +\n    geom_hline(yintercept = 0, color = \"red\",\n        lty = 2) + geom_pointrange(aes(ymin = X2.5..,\n    ymax = X97.5..)) + labs(x = \"Parameter\",\n    y = \"Effect size\") + coord_flip()\n\n\n\n\n\n\n\n\n\nWe should also check the diagnostic plots:\n\n\nCode\nplot_model(xy_mod_intr, type = \"diag\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\nModel interpretation\nCoefficients table:\n\n\n            Estimate Std. Error t value   Pr(&gt;|t|)\n(Intercept)  -4.1930    0.57023 -7.3532 2.6978e-09\nx1b           3.5974    0.80607  4.4629 5.1950e-05\nx2            1.3274    0.68161  1.9474 5.7610e-02\nx1b:x2       -2.9720    0.96227 -3.0885 3.4061e-03\n\n\n\nThe model found that \\(\\beta_1\\) (the effect size of ‘x1-b’ to ‘x1-a’) is 3.59741 and that it is significantly different from 0 (p-value = 5.19496^{-5})\nThe model found that \\(\\beta_2\\) (the effect size of ‘x2’) is 1.32735 and that it is significantly different from 0 (p-value = 0.05761). This is actually the slope of the relation between x2 and y when x1 = ‘a’\nThe model found that \\(\\beta_3\\) (the effect size of the interaction term ‘x1 * x2’) is -2.97196 and that it is significantly different from 0 (p-value = 0.00341). This is the difference between the slopes of x2 vs y when x1 = ‘a’ and x2 vs y when x1 = ‘b’.\nThe simulated values for the regression parameters can be compared to the summary of the lm() model to get a sense of the model precision:\n\n\\(\\beta_1\\) was set to 3 and was estimated as 3.597\n\\(\\beta_2\\) was set to 1.7 and was estimated as 1.327\n\\(\\beta_3\\) was set to -3 and was estimated as -2.972\n\n\n\n\n\nCase study\n\nChirino F, B Wilink, Araya-Salas M. In prep. Climatic factors affecting vocal activity in lemur leaf frogs.\n\n“Increased moonlight decreases the vocal activity of Agalychnis lemur* although this relationship is mediated by temperature*.”\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\nModified the code use to simulate a single associated predictor by gradually increasing the error. This is done by increasing the ‘sd’ argument in error &lt;- rnorm(n = n, sd = 2)\nTake a look at how larger errors affect inference (so you also need to run the models)\n\n\nNow replace the error term with error &lt;- rexp(n = n, rate = 0.2). This is creating an error with an exponential distribution (so non-normal). This is supposed to be problematic for the inferential power of these models. Compare the estimates you got to the simulation values (‘b0’ and ‘b1’). Explore the distribution of residuals (plot_model(model_name, type = \"diag\")) for both ‘normal’ and ‘exponential’ error models.\n\n\nCollinearity (the presence of correlated predictors) is supposed to affect the stability of multiple regression. The following code creates two highly collinear predictors (‘x1’ and ‘x2’). The last line of code shows the correlation between them.\n\n\n\nCode\n# set seed\nset.seed(123)\n\n# number of observations\nn &lt;- 50\nb0 &lt;- -4\nb1 &lt;- 3\nb2 &lt;- -2\nerror &lt;- rnorm(n = n, mean = 0, sd = 1)\n\n# random variables\nx1 &lt;- rnorm(n = n, mean = 0, sd = 1)\n\n# make x2 very similar to x2 (adding\n# little variation)\nx2 &lt;- x1 + rnorm(n = n, mean = 0, sd = 0.3)\n\ncor(x1, x2)\n\n\n[1] 0.94642\n\n\n\nBuild a multiple regression model for this data (y ~ x1 + x2). You can use the same code as in the section Adding more than 1 predictor: multiple regression.\nHow is the inference affected by the presence of collinear predictors? Make the diagnostic plots for this model (plot(model_name)).\nSimulate a data set with three predictors in which only two of them are highly collinear. Fit a multiple regression model (y ~ x1 + x2 + x3) for that data and look at how collinearity affects the estimate for the non-collinear predictor."
  },
  {
    "objectID": "linear_regression.html#generalized-linear-models",
    "href": "linear_regression.html#generalized-linear-models",
    "title": "Linear regression models",
    "section": "4.1 Generalized linear models",
    "text": "4.1 Generalized linear models\nGLM’s allow us to model the association to response variables that do not fit to a normal distribution. Furthermore, they allow to model distributions that more closely resemble the process that generated the data. The following data set creates a data set with a response representing counts (so non-normal):\n\n\nCode\nset.seed(1234)\n\n# sample size\nn &lt;- 50\n\n# regression coefficients\nb0 &lt;- 1.2\nb1 &lt;- 1.3\nb2 &lt;- 0\n\n\n# generate variables\ny &lt;- rpois(n = n, lambda = 6.5)  # lambda = average rate of success\nx2 &lt;- seq(-0.5, 0.5, , length(y))\nx1 &lt;- (log(y) - b0 - b2 * x2)/b1\n\n# create data frame\nxy_data_pois &lt;- data.frame(x1, x2, y)\n\nhead(xy_data_pois)\n\n\n\n\n\n\nx1\nx2\ny\n\n\n\n\n0.1433\n-0.5000\n4\n\n\n0.5738\n-0.4796\n7\n\n\n0.5738\n-0.4592\n7\n\n\n0.5738\n-0.4388\n7\n\n\n0.7671\n-0.4184\n9\n\n\n0.5738\n-0.3980\n7\n\n\n\n\n\n\nLet also plot ‘x1’ vs ‘y’:\n\n\nCode\n# plot\nggplot(xy_data_pois, aes(x = x1, y = y)) +\n    geom_point()  # plot points\n\n\n\n\n\n\n\n\n\nThe relation does not seem very linear nor the variance seems to be constant across ‘x1’.\nWe can relaxed the normal distribution requirement with GLMs. glm() is a base R function that help us do the trick. For this example the most appropriate distribution is Poisson. This can be set in the ‘family’ argument like this:\n\n\nCode\nglm_pois &lt;- glm(formula = y ~ x1 + x2, data = xy_data_pois,\n    family = poisson())\n\n\nAs you can see the only extra argument compared to lm() is ‘family’. The rest is just the ‘formula’ and ‘data’ we are already familiar with. So again, we can build upon of our knowledge on linear models to extend them to more complex data structures.\nWe also need to run summary() to get model output:\n\n\nCode\nsummary(glm_pois)\n\n\n\nCall:\nglm(formula = y ~ x1 + x2, family = poisson(), data = xy_data_pois)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) 1.20e+00   1.29e-01    9.31  &lt; 2e-16 ***\nx1          1.30e+00   2.20e-01    5.92  3.2e-09 ***\nx2          1.39e-16   1.90e-01    0.00        1    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3.9471e+01  on 49  degrees of freedom\nResidual deviance: 2.2204e-16  on 47  degrees of freedom\nAIC: 186.9\n\nNumber of Fisher Scoring iterations: 3\n\n\n\nModel interpretation\nCoefficients table:\n\n\n              Estimate Std. Error    z value   Pr(&gt;|z|)\n(Intercept) 1.2000e+00    0.12889 9.3106e+00 1.2709e-20\nx1          1.3000e+00    0.21960 5.9200e+00 3.2198e-09\nx2          1.3882e-16    0.19016 7.3003e-16 1.0000e+00\n\n\n\nThe model tells us that \\(\\beta_1\\) (the effect size of ‘x1’) is 1.3 and that it is significantly different from 0 (p-value = 3.21981^{-9}). This is actually interpreted as an increase in 1 unit of ‘x1’ results in ‘y’ (rate) by a factor of exp(1.3) = 3.6693.\nThe model also tells us that \\(\\beta_2\\) (the effect size of ‘x2’) is 1.38824^{-16} and that it is significantly different from 0 (p-value = 1). This is means that an increase in 1 unit of ‘x2’ results in ‘y’ (rate) by a factor of exp(1.38824^{-16}) = 1.\n\n\n\nExercise\n\nTry fitting a lm() model (so with a gaussian distribution), compare the results and check the residuals (plot_model(model_name, type = \"diag\"))\n\n\nMany other distribution and link functions are available:"
  },
  {
    "objectID": "linear_regression.html#mixed-effect-models",
    "href": "linear_regression.html#mixed-effect-models",
    "title": "Linear regression models",
    "section": "4.2 Mixed-effect models",
    "text": "4.2 Mixed-effect models\nSometimes our data sets include additional levels of structure. For instance, when we sample several individuals from different populations. In those cases variation at the higher structural level (populations) might preclude detecting patterns at the lower level (individuals).\nLet’s simulate some data that resembles that scenario. We have two continuous predictor (x1) and a continuous response (y). Each sample comes from 1 of 8 different populations (pops):\n\n\nCode\n# x&lt;- 1 set seed\nset.seed(28)\n\n# number of observations\nn &lt;- 300\nb0 &lt;- 1\nb1 &lt;- 1.3\npops &lt;- sample(0:8, size = n, replace = TRUE)\nerror &lt;- rnorm(n = n, mean = 0, sd = 2)\n\n# random variables\nx1 &lt;- rnorm(n = n, mean = 0, sd = 1)\ny &lt;- b0 + pops * 2 + b1 * x1 + error\n\n# add letters\npops &lt;- letters[pops + 1]\n\n# create data set\nxy_data_pops &lt;- data.frame(x1, y, pops)\n\nhead(xy_data_pops, 10)\n\n\n\n\n\n\nx1\ny\npops\n\n\n\n\n1.5461\n3.3378\na\n\n\n0.5683\n3.1400\na\n\n\n-0.6385\n15.2824\ni\n\n\n0.9842\n2.6610\na\n\n\n1.0536\n3.7312\nb\n\n\n-0.8229\n3.0189\na\n\n\n-1.3237\n3.2186\nc\n\n\n2.1785\n19.0542\ni\n\n\n2.2648\n15.4549\ni\n\n\n-0.7784\n11.6670\nh\n\n\n\n\n\n\nWe can explore the relation between y and x1 with a plot:\n\n\nCode\nggplot(data = xy_data_pops, aes(x = x1, y = y)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\ncan you clearly see the pattern of association between the two variables we used to simulate the data? We can further explore the data with a simple linear regression model:\n\n\nCode\nsummary(lm(y ~ x1, data = xy_data_pops))\n\n\n\nCall:\nlm(formula = y ~ x1, data = xy_data_pops)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.755  -5.119   0.186   4.602  12.409 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    8.852      0.325   27.21   &lt;2e-16 ***\nx1             0.633      0.329    1.92    0.055 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.63 on 298 degrees of freedom\nMultiple R-squared:  0.0123,    Adjusted R-squared:  0.00895 \nF-statistic:  3.7 on 1 and 298 DF,  p-value: 0.0554\n\n\nDespite having simulated a non-zero \\(\\beta_1\\) we have no significant association according to this model and the estimated for \\(\\beta_1\\) is far from the simulated one. This poor inference is due to the fact that we are ignoring an important feature of our data, the grouping of samples in ‘populations’.\nMixed-effect models (a.k.a. multi-level models or varying effect models) can help us account for these additional features, significantly improving our inferential power. Let’s color each of the populations to see how the variables co-vary for each data sub-group:\n\n\nCode\nggplot(data = xy_data_pops, aes(x = x1, y = y,\n    color = pops)) + geom_point()\n\n\n\n\n\n\n\n\n\nThere seems to be a clear pattern of positive association between x1 and y. The pattern becomes a bit more obvious if we plot each population in its own panel:\n\n\nCode\nggplot(data = xy_data_pops, aes(x = x1, y = y,\n    color = pops)) + geom_point() + facet_wrap(~pops) +\n    geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\nLet’s build a mixed-effect model using population as a varying intercept:\n\n\nCode\nmix_eff_mod &lt;- lmer(formula = y ~ x1 + (1 |\n    pops))\n\nsummary(mix_eff_mod)\n\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: y ~ x1 + (1 | pops)\n\nREML criterion at convergence: 1296.4\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.524 -0.657 -0.032  0.612  3.245 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n pops     (Intercept) 30.07    5.48    \n Residual              3.76    1.94    \nNumber of obs: 300, groups:  pops, 9\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)    8.788      1.831   8.003     4.8   0.0014 ** \nx1             1.317      0.115 290.068    11.4   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n   (Intr)\nx1 -0.003\n\n\nThe model correctly detected the simulated pattern and the estimate for \\(\\beta_1\\) (1.31665) is very close to the simulated value."
  },
  {
    "objectID": "linear_regression.html#references",
    "href": "linear_regression.html#references",
    "title": "Linear regression models",
    "section": "4.3 References",
    "text": "4.3 References\n\nRichard McElreath’s Statistical Rethinking book\nR’s rbinom – Simulate Binomial or Bernoulli trials\nR’s rnorm – selecting values from a normal distribution\nR’s exp – Simulating Exponential Distributions\nSimulating data in R"
  },
  {
    "objectID": "ggplot2.html",
    "href": "ggplot2.html",
    "title": "Elegant graphs with ggplot2",
    "section": "",
    "text": "Understand the logic used by ggplot2 to structure graphs\nGet familiar with its basic functions and types layer"
  },
  {
    "objectID": "ggplot2.html#grammar-of-graphics",
    "href": "ggplot2.html#grammar-of-graphics",
    "title": "Elegant graphs with ggplot2",
    "section": "0.1 Grammar of graphics",
    "text": "0.1 Grammar of graphics\nThe main idea is to start with a base layer of raw data and then add more layers of annotations and statistical summaries. The package allows us to produce graphics using the same structure of thought that we use when designing an analysis, reducing the distance of how we visualize a graphic in the head and the final product.\nLearning the grammar will not only be crucial to produce a graph of interest, but also to think about other more complex graphs. The advantage of this grammar is the possibility to create new graphs composed of new combinations of elements."
  },
  {
    "objectID": "ggplot2.html#graph-components",
    "href": "ggplot2.html#graph-components",
    "title": "Elegant graphs with ggplot2",
    "section": "0.2 Graph components",
    "text": "0.2 Graph components\nAll ggplot2 graphs contain the following components:\n\nData - The R object with the information that needs to be plotted\nlayers - The specific data that will be plotted (e.g. ‘x’ & ‘y’)\nscale - The range of the data to be included\ncoord. - Coordinate system (not used very often)\nfacet - determines how to break the data in subplots in a multipanel\ntheme - controls the plot style  \n\nThis components are put together using “+”.\nThe most common syntax includes the data within the “ggplot” call and a “geom_” layer.\n \nFirst install/load the package:\n\n\nCode\n# install\ninstall.packages(\"ggplot2\")\n\n# load library\nlibrary(ggplot2)"
  },
  {
    "objectID": "ggplot2.html#scatter-plots",
    "href": "ggplot2.html#scatter-plots",
    "title": "Elegant graphs with ggplot2",
    "section": "0.3 Scatter plots",
    "text": "0.3 Scatter plots\nLet’s use the “iris” data set to create scatter plots:\n\n\nCode\nggplot(data = iris, mapping = aes(x = Sepal.Length, y = Petal.Length)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\n \nThis plot is defined by 3 components: 1. “data”- iris 1. “aes” - Sepal.length vs Petal.length 1. “layer” - Points (geom)"
  },
  {
    "objectID": "ggplot2.html#aesthetic-attributes",
    "href": "ggplot2.html#aesthetic-attributes",
    "title": "Elegant graphs with ggplot2",
    "section": "3.1 Aesthetic attributes",
    "text": "3.1 Aesthetic attributes\nWe can also add other aesthetic attributes like color, shape and size. This attributes can be included within aes():\n\n\nCode\n# color by species\nggplot(data = iris, mapping = aes(x = Sepal.Length, y = Petal.Length,\n    color = Species)) + geom_point()\n\n\n\n\n\n\n\n\n\nCode\n# color and shape by species\nggplot(data = iris, mapping = aes(x = Sepal.Length, y = Petal.Length,\n    color = Species, shape = Species)) + geom_point()\n\n\n\n\n\n\n\n\n\n \nNote that the aesthetic arguments can also be included in the “geom” layer:\n\n\nCode\nggplot(data = iris, mapping = aes(x = Sepal.Length, y = Petal.Length)) +\n    geom_point(aes(color = Species, shape = Species))\n\n\n\n\n\n\n\n\n\n \nWe can also include a fixed value:\n\n\nCode\nggplot(data = iris, mapping = aes(x = Sepal.Length, y = Petal.Length)) +\n    geom_point(color = \"red2\")\n\n\n\n\n\n\n\n\n\n \nSome attributes work better with some data types:\n\nColor and shape: categorical variables\nSize: continuous variables\n\n \n\n\nExercise 1\nUsing the “hylaeformis” data set (it can also be downloaded here):\n\n\nCode\n# read from website\nhylaeformis_data &lt;- read.csv(\"https://raw.githubusercontent.com/maRce10/OTS_Tropical_Biology_2023/master/data/hylaeformis_data.csv\",\n    stringsAsFactors = FALSE)\n\n# if download manually read it from the local file\n# hylaeformis_data &lt;- read.csv('hylaeformis_data.csv',\n# stringsAsFactors = FALSE)\n\nhead(hylaeformis_data, 20)\n\n\n\n1.1 Create a scatter plot of “duration” vs “meanfreq” (mean frequency)\n1.2 Add a aesthetic attribute to show a different color for each locality\n1.3 Add another aesthetic attribute to show “dfrange” (dominant frequency range) as the shape size"
  },
  {
    "objectID": "ggplot2.html#multipanel-plots-facetting",
    "href": "ggplot2.html#multipanel-plots-facetting",
    "title": "Elegant graphs with ggplot2",
    "section": "3.2 Multipanel plots (Facetting)",
    "text": "3.2 Multipanel plots (Facetting)\n\nAnother way to visualize categorical variables\nAllows to create multipanel plots for each level of the variable\n2 types: “grid” & “wrap”\n\n\n\nCode\nggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() + facet_wrap(~Species)\n\n\n\n\n\n\n\n\n\nCode\n# or\n\nggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() + facet_grid(~Species)\n\n\n\n\n\n\n\n\n\n \nThe scale can be fixed or free for the x and y axis, and the number of columns and rows can be modified:\n\n\nCode\n# free x\nggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() + facet_wrap(~Species,\n    scales = \"free_x\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# free x and 3 rows\nggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() + facet_wrap(~Species,\n    scales = \"free_y\", nrow = 3)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# both free and 2 rows\nggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() + facet_wrap(~Species,\n    scales = \"free\", nrow = 2)\n\n\n\n\n\n\n\n\n\n \nNote that we can also saved the basic component as an R object and add other components later in the code:\n\n\nCode\np &lt;- ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point()\n\np + facet_wrap(~Species, scales = \"free_x\", nrow = 3)"
  },
  {
    "objectID": "ggplot2.html#additional-geoms",
    "href": "ggplot2.html#additional-geoms",
    "title": "Elegant graphs with ggplot2",
    "section": "3.3 Additional “geoms”",
    "text": "3.3 Additional “geoms”\n\ngeom_smooth() - adds best fit lines (including CI)\ngeom_boxplot()\ngeom_histogram() & geom_freqpoly() - frequency distributions\ngeom_bar() - frequency distribution of categorical variables\ngeom_path() & geom_line() - add lines to scatter plots\n\n \n\n3.3.1 geom_smooth()\nBest fit regression lines can be added with geom_smooth():\n\n\nCode\n# smoother and CI\nggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() + geom_smooth(method = \"lm\") +\n    facet_wrap(~Species, scales = \"free\", nrow = 3)\n\n\n\n\n\n\n\n\n\nCode\n# without CI\nggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() + geom_smooth(method = \"lm\",\n    se = FALSE) + facet_wrap(~Species, scales = \"free\", nrow = 3)\n\n\n\n\n\n\n\n\n\n \n\nExercise 2\nUsing the “msleep” example data set:\n\n2.1 Create a scatter plot of “bodywt”(body weight) vs “brainwt” (brain weight)\n\n2.2 Add “order” as a color aesthetic\n\n2.3 Add a “facet” component to split plots by order using free scales\n\n2.4 Remove the orders with less than 4 species in the data set and make a plot similar to 2.3\n\n2.5 Add a smooth line to each plot in the panel\n\n\n\n\n3.3.2 Boxplots\nAgain, it only takes a new “geom” component to create a boxplot:\n\n\nCode\nggplot(iris, aes(Species, Petal.Length)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\nAn interesting alternative are the violin plots:\n\n\nCode\nggplot(iris, aes(Species, Petal.Length)) + geom_violin()\n\n\n\n\n\n\n\n\n\n \n\n\n3.3.3 Histograms\nSame thing with histrograms and frequency plots:\n\n\nCode\nggplot(iris, aes(Petal.Length)) + geom_histogram()\n\n\n\n\n\n\n\n\n\nCode\nggplot(iris, aes(Petal.Length)) + geom_freqpoly()\n\n\n\n\n\n\n\n\n\nCode\nggplot(iris, aes(Petal.Length)) + geom_histogram() + geom_freqpoly()\n\n\n\n\n\n\n\n\n\n \nWe can control the width of the bars:\n\n\nCode\nggplot(iris, aes(Petal.Length)) + geom_histogram(binwidth = 1, fill = adjustcolor(\"red2\",\n    alpha.f = 0.3))\n\n\nWarning: Duplicated aesthetics after name standardisation: fill\n\n\n\n\n\n\n\n\n\n \nAnd compare the distribution of different groups within the same histogram:\n\n\nCode\nggplot(iris, aes(Petal.Length, fill = Species)) + geom_histogram(binwidth = 0.4)\n\n\n\n\n\n\n\n\n\n \n\n\n3.3.4 Bar plots\nShow the distribution of discrete (categorical) variables:\n\n\nCode\ntab &lt;- table(msleep$order)\n\ndf &lt;- as.data.frame(table(msleep$order[msleep$order %in% names(tab)[tab &gt;\n    3]]))\n\nggplot(df, aes(Var1, Freq)) + geom_bar(stat = \"identity\")"
  },
  {
    "objectID": "ggplot2.html#customizing-ggplots",
    "href": "ggplot2.html#customizing-ggplots",
    "title": "Elegant graphs with ggplot2",
    "section": "3.4 Customizing ggplots",
    "text": "3.4 Customizing ggplots\nBesides the basic functions (e.g. components) described above, ggplot has many other tools (both arguments and additional functions) to further customize plots. Pretty much every thing can be modified. Here we see some of the most common tools.\n \n\n3.4.1 Themes\nggplot2 comes with some default themes that can be easily applied to modified the look of our plots:\n\n\nCode\np &lt;- ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point()\n\np + theme_classic()\n\n\n\n\n\n\n\n\n\nCode\np + theme_bw()\n\n\n\n\n\n\n\n\n\nCode\np + theme_minimal()\n\n\n\n\n\n\n\n\n\n \nMost themes differ in the use of grids, border lines and axis labeling patterns.\n \n\n\n3.4.2 Axis customization\nAxis limits can be modified as follows:\n\n\nCode\nggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() + xlim(c(0,\n    10))\n\n\n\n\n\n\n\n\n\nCode\nggplot(iris, aes(Sepal.Length, Petal.Length, col = Species)) + geom_point() +\n    xlim(c(0, 10)) + ylim(c(0, 9))\n\n\n\n\n\n\n\n\n\n \nAxis can also be transformed:\n\n\nCode\nggplot(iris, aes(Sepal.Length, Petal.Length, col = Species)) + geom_point() +\n    scale_x_continuous(trans = \"log\") + scale_y_continuous(trans = \"log2\")\n\n\n\n\n\n\n\n\n\n \nor reversed:\n\n\nCode\nggplot(iris, aes(Sepal.Length, Petal.Length, col = Species)) + geom_point() +\n    scale_y_reverse()\n\n\n\n\n\n\n\n\n\n\n\n3.4.3 Saving ggplots\nggplots can be exported as image files using the ggsave function:\n\n\nCode\nggplot(data = msleep[msleep$order %in% names(tab)[tab &gt; 5], ], mapping = aes(x = bodywt,\n    y = brainwt)) + geom_point() + facet_wrap(~order, scales = \"free\")\n\n\nWarning: Removed 21 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nCode\n# Export\nggsave(\"plot.png\", width = 5, height = 5)\n\n\nWarning: Removed 21 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n \nThe image file type will be identify by the extension in the file name\n \nAdditional axis customizing:\n\n\nCode\n# Log2 scaling of the y axis (with visually-equal spacing)\nrequire(scales)\n\np + scale_y_continuous(trans = log2_trans())\n\n\n\n\n\n\n\n\n\nCode\n# show exponents\np + scale_y_continuous(trans = log2_trans(), breaks = trans_breaks(\"log2\",\n    function(x) 2^x), labels = trans_format(\"log2\", math_format(2^.x)))\n\n\n\n\n\n\n\n\n\nCode\n# Percent\np + scale_y_continuous(labels = percent)\n\n\n\n\n\n\n\n\n\nCode\n# dollar\np + scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n\n\nCode\n# scientific\np + scale_y_continuous(labels = scientific)\n\n\n\n\n\n\n\n\n\nCode\n### Agregar 'tick marks' ###\n\n# Cargar librerías\nlibrary(MASS)\n\ndata(Animals)\n\n# x and y axis are transformed and formatted\np2 &lt;- ggplot(Animals, aes(x = body, y = brain)) + geom_point(size = 4) +\n    scale_x_log10(breaks = trans_breaks(\"log10\", function(x) 10^x),\n        labels = trans_format(\"log10\", math_format(10^.x))) + scale_y_log10(breaks = trans_breaks(\"log10\",\n    function(x) 10^x), labels = trans_format(\"log10\", math_format(10^.x))) +\n    theme_bw()\n\n# log-log plot without log tick marks\np2\n\n\n\n\n\n\n\n\n\nCode\n# Show log tick marks\np2 + annotation_logticks()\n\n\n\n\n\n\n\n\n\nCode\n# # Log ticks on left and right\np2 + annotation_logticks(sides = \"lr\")\n\n\n\n\n\n\n\n\n\nCode\n# All sides\np2 + annotation_logticks(sides = \"trbl\")\n\n\n\n\n\n\n\n\n\n \n\n\n3.4.4 Other graphs\nMany other types of graphs can be generated. Here I show a single example of cool contour and “heatmap” graphs:\n\n\nCode\nhead(faithful)\n\n\n\n\n\n\neruptions\nwaiting\n\n\n\n\n3.60\n79\n\n\n1.80\n54\n\n\n3.33\n74\n\n\n2.28\n62\n\n\n4.53\n85\n\n\n2.88\n55\n\n\n\n\n\n\nCode\nggplot(faithfuld, aes(eruptions, waiting)) + geom_contour(aes(z = density,\n    colour = ..level..))\n\n\nWarning: The dot-dot notation (`..level..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(level)` instead.\n\n\n\n\n\n\n\n\n\nCode\nggplot(faithfuld, aes(eruptions, waiting)) + geom_raster(aes(fill = density))"
  },
  {
    "objectID": "ggplot2.html#other-r-graphing-packages",
    "href": "ggplot2.html#other-r-graphing-packages",
    "title": "Elegant graphs with ggplot2",
    "section": "3.5 Other R graphing packages",
    "text": "3.5 Other R graphing packages\n\nggvis (interactive ggplots)\nvcd (Warnes 2015)\nplotrix (Lemon et al. 2006)\ngplots (Warnes 2015)\n\nCheck the CRAN Graphics Task View for a more comprehensive list of graphical tools in R."
  },
  {
    "objectID": "ggplot2.html#references",
    "href": "ggplot2.html#references",
    "title": "Elegant graphs with ggplot2",
    "section": "3.6 References",
    "text": "3.6 References\n\nLemon J (2006) Plotrix: a package in the red light district of R. R-News 6(4):8–12\nWarnes GR, Bolker B, Bonebakker L, Gentleman R, Liaw WHA, Lumley T, Maechler M, Magnusson A, Moeller S, Schwartz M, Venables B (2015) gplots: various R programming tools for plotting data. R package version 2.17.0. https://CRAN.R-project.org/package=gplots\nWickham H (2010) A layered grammar of graphics. J Comput Graph Stat 19(1):3–28\nWilkinson L (2005) The grammar of graphics. Statistics and computing, 2nd edn. Springer, New York\n\n\nSession information\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.2 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: America/Costa_Rica\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] scales_1.3.0       viridis_0.6.5      viridisLite_0.4.2  MASS_7.3-55       \n[5] RColorBrewer_1.1-3 ggplot2_3.5.1      knitr_1.48         kableExtra_1.4.0  \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.4        generics_0.1.3    xml2_1.3.6        stringi_1.8.4    \n [5] lattice_0.20-45   digest_0.6.37     magrittr_2.0.3    evaluate_0.24.0  \n [9] grid_4.3.2        fastmap_1.2.0     jsonlite_1.8.8    Matrix_1.6-5     \n[13] formatR_1.14      gridExtra_2.3     mgcv_1.8-39       fansi_1.0.6      \n[17] isoband_0.2.7     textshaping_0.3.7 cli_3.6.3         rlang_1.1.4      \n[21] munsell_0.5.1     splines_4.3.2     withr_3.0.1       yaml_2.3.10      \n[25] tools_4.3.2       dplyr_1.1.4       colorspace_2.1-1  vctrs_0.6.5      \n[29] R6_2.5.1          lifecycle_1.0.4   stringr_1.5.1     htmlwidgets_1.6.4\n[33] ragg_1.2.7        pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.5     \n[37] glue_1.7.0        systemfonts_1.1.0 xfun_0.47         tibble_3.2.1     \n[41] tidyselect_1.2.1  highr_0.11        rstudioapi_0.16.0 farver_2.1.2     \n[45] htmltools_0.5.8.1 nlme_3.1-155      rmarkdown_2.28    svglite_2.1.3    \n[49] labeling_0.4.3    compiler_4.3.2"
  }
]