---
title: <font size="7"><b>Simulating data in R</b></font>
---

```{r,echo=FALSE,message=FALSE}

options("digits"=5)
options("digits.secs"=3)

# options to customize chunk outputs
knitr::opts_chunk$set(
  message = FALSE
 )

```

::: {.alert .alert-info}
# Objectives {.unnumbered .unlisted}

- Get familiar with the basic random generating functions in R

- Use of simulated data to understand the behavior of statistical tools 

:::

```{r, echo = FALSE, message=FALSE}

library(kableExtra)
library(knitr)
library(ggplot2)
library(viridis)

tibble <- function(x, ...) { 
  x <- kbl(x, digits=4, align= 'c', row.names = FALSE) 
   x <- kable_styling(x, position ="center", full_width = FALSE,  bootstrap_options = c("striped", "hover", "condensed", "responsive")) 
   asis_output(x)
}

registerS3method("knit_print", "data.frame", tibble)

# ggplot settings
geom_histogram <- function(...) ggplot2::geom_histogram(..., fill = viridis(10, alpha = 0.5)[8], show.legend = FALSE, bins = 20, color = "black")

geom_smooth <- function(...) ggplot2::geom_smooth(..., color = viridis(10,  alpha = 0.5)[8])

geom_boxplot <- function(...) ggplot2::geom_boxplot(..., fill = viridis(10, alpha = 0.5)[7])

geom_pointrange <- function(...) ggplot2::geom_pointrange(..., show.legend = FALSE, color = viridis(10, alpha = 0.5)[7], size = 2) 

plot_model <- function(...) sjPlot::plot_model(xy_mod, type = "diag", colors = viridis(10, alpha = 0.5)[7])

theme_set(theme_classic(base_size = 20))

```

```{r setup, include = FALSE}

knitr::opts_chunk$set(
  tidy.opts = list(width.cutoff = 40), 
  tidy = TRUE,
  message = FALSE
 )

```

Please load the following packages:
```{r, eval = FALSE}

library(ggplot2)
library(viridis)

```

# Generating random numbers in R

Statistics allow us to infer patterns in the data. We tend to use real data sets to teach stats. However, it might get circular to understand the inner working of an statistical tool by testing its ability to infer a pattern that we are not sure its found in the data (and have no idea on the mechanism producing that pattern). **Simulations allow us to create controlled scenarios in which we know for sure the patterns** present in the data and the underlying processes that generated them.

R offers some basic functions for data simulation. The most used ones are the random number generating functions. The names of these functions all start with *r* (`r____()`). For instance `runif()`:
```{r, echo=FALSE}
set.seed(7)
```


```{r}

unif_var <- runif(n = 100, min = 0, max = 10)

```
&nbsp; 

The output is a numeric vector of length 1 thousand (`n = 100`):

```{r}

unif_var

```


We can explore the output by plotting a histogram:

```{r}

# create histogram
ggplot(data = data.frame(unif_var), mapping = aes(x = unif_var)) + geom_histogram() 

```
&nbsp; 

It shows a uniform distribution ranging from 0 to 10. 

We can also simulate random numbers coming from a normal distribution using `rnorm()`:

```{r}

# create random variable
norm_var <- rnorm(n = 1000, mean = 2, sd = 1)

# plot histogram
ggplot(data = data.frame(norm_var), mapping = aes(x = norm_var)) + geom_histogram() 

```

&nbsp; 

Note that random number generating functions all have the argument 'n', which sets the length of the output vector (i.e. number of random numbers), plus some additional arguments related to specific parameters of the distribution.

Continuous variables (i.e. numeric vectors) can be converted to discrete variables (i.e. integer numbers) simply by rounding them:

```{r}

v1 <- rnorm(n = 5, mean = 10, sd = 3)

v1

round(x = v1, digits = 0)

```
&nbsp; 

<div class="alert alert-info">

<font size="5">Exercise</font> 

- What do the functions `rbinom()` and `rexp()` do? (tip: run `?rexp`)

- Run them and make histograms of their output
 
- What do the arguments 'mean' and 'sd' in `rnorm()` do? Play with different values and check the histogram to get a sense of their effect in the simulation

</div>

&nbsp; 

## Generating categorical variables

The easiest way to generate categorical variables is to use the 'letters' (or 'LETTERS') example vector to assign category levels. We can do this using the function `rep()`. For instance, the following code creates a categorical (character) vector with two levels, each one with 4 observations:

```{r}

rep(x = letters[1:2], each = 4)

```
&nbsp; 

We can also replicate this pattern using the argument 'times'. This code replicates the previous vector 2 times:

```{r}

rep(x = letters[1:2], each = 4, times = 2)

```
&nbsp; 

Another option is to simulate a variable from a binomial distribution and then convert it into a factor:

```{r}
# run rbinom
binom_var <- rbinom(n = 50, size = 1, prob = 0.5)

binom_var
```


```{r}
categ_var <- factor(binom_var, labels = c("a", "b"))

categ_var
```
&nbsp; 

## Random sampling

The other important R tool for playing with simulated data is `sample()`. This function allows you to take samples of specific sizes from vectors. For instance, take the example vector `letters`:

```{r}

letters

```
&nbsp; 

We can take a sample of this vector like is:

```{r}

sample(x = letters, size = 10)

```
&nbsp; 

The argument 'size'  allow us to determine the size of the sample. Note that we get an error if the size is larger than the vector itself:

```{r, error=TRUE}

sample(x = letters, size = 30)

```
&nbsp; 

This can only be done when sampling with replacement. Sampling with replacement can be applied by setting the argument `replace = TRUE`:

```{r}

sample(x = letters, size = 30, replace = TRUE)

```
&nbsp; 

## Iterating a process

Often simulations most be repeated several times to rule out spurious results due to chance or just to try different parameters. The functions for simulating data mentioned above can be run several times (e.g. iterated) using the function `replicate()`:

```{r}

repl_rnorm <- replicate(n = 3, expr = rnorm(2), simplify = FALSE)

class(repl_rnorm)

repl_rnorm
```
&nbsp; 

## Making simulations reproducible

The last trick we need to run simulations in R is the ability to reproduce a simulation (i.e. get the exact same simulated data and results). This can be useful for allowing other researchers to run our analyses in the exact same way. This can be easily done with the function `set.seed()`. Try running the following code. You should get the same output:

```{r}

set.seed(10)

runif(n = 2)

```

---


# Creating data sets
    
## Datasets with numeric and categorical data

Now that we know how to simulate continuous and categorical variable. We can put them together to create simulated data sets. This can be done using the function `data.frame()`:

```{r}

# create categorical variable
group <- rep(x = letters[1:2], each = 3)

# create continous data
size <- rnorm(n = 6, mean = 5, sd = 1)

# put them together in a data frame
df <- data.frame(group, size)

# print
df

```

Of course, we could add more variables to this data frame:

```{r}


# create categorical variable
group <- rep(x = letters[1:2], each = 3)
individual <- LETTERS[1:6]

# create continous data
size <- rnorm(n = 6, mean = 5, sd = 1)
weight <- rnorm(n = 6, mean = 100, sd = 10)


# put them together in a data frame
df <- data.frame(group, individual, size, weight)

# print
df

```

And that's a simulated data set in its most basic form. That looks a lot like the kind of data we use to work with in the biological science.

---

# How to use simulated data to understand the behavior of statistical tools

## A proof of concept: *the Central Limit Theorem*

The [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) states that, if we take repeated random samples of a population, the means of those samples will conform to a normal distribution, even if the population is not normally distributed. In addition, the resulting normal distribution must have a mean close to the population's mean. The theorem is a key concept for inferential statistics as it implies that statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions. Nonetheless, the point here is only to showcase how simulations can be used to understand the behavior statistical methods.  

To check if those basic claims about the Central Limit Theorem hold true we can use simulated data in R. Let's simulate a 1000 observation population with a uniform distribution: 

```{r, eval=FALSE}
# simulate uniform population
unif_pop <- runif(n = 1000, min = 0, max = 10)

# check distribution/ plot histogram
ggplot(data = data.frame(unif_pop), mapping = aes(x = unif_pop)) + geom_histogram() 

```

```{r, echo=FALSE}
set.seed(10)

# simulate uniform population
unif_pop <- runif(n = 1000, min = 0, max = 10)

# check distribution/ plot histogram
ggplot(data = data.frame(unif_pop), mapping = aes(x = unif_pop)) + geom_histogram() 


```

&nbsp; 

We can take random samples using `sample()` like this:

```{r}

sample(x = unif_pop, size = 30)

```
&nbsp; 
 
This process can be replicated several times with `replicate()`: 

```{r}

samples <- replicate(n = 100, expr = mean(sample(x = unif_pop, size = 30)))

```
&nbsp; 

The code above takes 100 samples with 30 values each. We can now check the distribution of the samples: 

```{r, eval=FALSE}

# check distribution/ plot histogram
ggplot(data = data.frame(samples), mapping = aes(x = samples)) + geom_histogram() 


```

```{r, echo=FALSE}

# check distribution/ plot histogram
ggplot(data = data.frame(samples), mapping = aes(x = samples)) + geom_histogram() 

```
&nbsp; 

... as well as the mean:

```{r}

mean(samples)

```
&nbsp; 

As expected, the samples follows a normal distribution with a mean close to the mean of the population, which is:

```{r}

mean(unif_pop)

```
&nbsp;

Let's try with a more complex distribution. For instance, a bimodal distribution:

```{r, eval=FALSE}

# set seed
set.seed(123)

# simulate variables
norm1 <- rnorm(n = 1000, mean = 10, sd = 3)
norm2 <- rnorm(n = 1000, mean = 20, sd = 3)

# add them in a single one
bimod_pop <- c(norm1, norm2)

# check distribution/ plot histogram
ggplot(data = data.frame(bimod_pop), mapping = aes(x = bimod_pop)) + geom_histogram() 

```

```{r, echo=FALSE}

# set seed
set.seed(123)

norm1 <- rnorm(n = 1000, mean = 10, sd = 3)
norm2 <- rnorm(n = 1000, mean = 20, sd = 3)

bimod_pop <- c(norm1, norm2)

# check distribution/ plot histogram
ggplot(data = data.frame(bimod_pop), mapping = aes(x = bimod_pop)) + geom_histogram() 
```

```{r, eval=FALSE}

samples <- replicate(200, mean(sample(bimod_pop, 10)))

# check distribution/ plot histogram
ggplot(data = data.frame(samples), mapping = aes(x = samples)) + geom_histogram() 

```

```{r, echo=FALSE}

samples <- replicate(200, mean(sample(bimod_pop, 10)))

# check distribution/ plot histogram
ggplot(data = data.frame(samples), mapping = aes(x = samples)) + geom_histogram() 

```


```{r}
mean(samples)

mean(bimod_pop)
```
&nbsp;

<div class="alert alert-info">

<font size="5">Exercise</font> 

&nbsp;

- Try exploring the Central Limit Theorem as above but this time using:
    
    1. An exponential distribution (`rexp()`) 
    1. A binomial distribution (`rbinom()`) 

&nbsp;

- For each distribution: plot a histogram and compare the means of the population and the samples

</div>

---

## References {.unnumbered .unlisted}

- [R's rbinom – Simulate Binomial or Bernoulli trials](https://www.programmingr.com/examples/neat-tricks/sample-r-function/r-rbinom/)

- [R's rnorm – selecting values from a normal distribution](https://www.programmingr.com/examples/neat-tricks/sample-r-function/r-rnorm/)

- [R's exp – Simulating Exponential Distributions](https://www.programmingr.com/examples/neat-tricks/sample-r-function/rexp/)

- [Simulating data in R](https://aosmith.rbind.io/2018/08/29/getting-started-simulating-data/)


---

# Session information {.unnumbered .unlisted}

```{r session info, echo=F}

sessionInfo()

```
